[
  {
    "objectID": "transition-from-rmarkdown.html",
    "href": "transition-from-rmarkdown.html",
    "title": "Transition from RMarkdown",
    "section": "",
    "text": "You may already have workflows in RMarkdown and are interested in transitioning to Quarto. There’s no hurry to migrate to Quarto. Keep using Rmarkdown and when you’re ready the migration will be fine.\nHere are some notes as we migrate RMarkdown sites and books.\nTODO: translating R code chunks"
  },
  {
    "objectID": "transition-from-rmarkdown.html#bookdown-to-quarto",
    "href": "transition-from-rmarkdown.html#bookdown-to-quarto",
    "title": "Transition from RMarkdown",
    "section": "Bookdown to Quarto",
    "text": "Bookdown to Quarto\nConverting a Bookdown book to Quarto is slightly more involved than converting a website. A book has chapters whose order must be defined, and likely has citations and cross-refs. Still, conversion is not that hard.\nWe got some practice converting from Bookdown to Quarto by helping Gavin Fay convert his lab’s fantastic onboarding documentation, the Faylab Lab Manual. Here’s the GitHub view before and after.\nOur best first reference material for this was Nick Tierney’s Notes on Changing from Rmarkdown/Bookdown to Quarto. Nick shares some scripts in that post to automate some changes. In our case, the book was small enough that we made all changes manually. Quarto documentation was indispensable.\n\nExperimenting in a low-risk environment\nWe forked a copy of the Faylab Lab manual to the Openscapes organization, and worked in a branch so we could make changes relatively risk-free. We could always fork a new copy of the original if we “broke” something. (Caution: the default when making a pull request from a fork is to push changes to the original upstream repo, not your fork and it does this without warning if you have write-access to that repo.) With local previews it’s easy to test / play with settings to see what they do. We tended to make a change, Preview, then compare the look and functionality of the book to the original. It was helpful to comment out some elements of the configuration file _output.yml after their counterparts had been added to the Quarto configuration file _quarto.yml, or to confirm they were no longer needed, before making the drastic move of deleting them.\n\n\nThe conversion\nHere are the main steps to convert the Faylab Lab manual from Bookdown to Quarto.\nCreate new empty file called _quarto.yml and add book metadata there. The screenshots below\nSet project type as book.\nMove metadata out of index.qmd and into _quarto.yml. Title, author, and publication date were in index.qmd with date set using date: \"Last updated:r Sys.Date()\". Now these are in _quarto.yml with date set using date: last-modified. Note that having R code would require you to adjust code chunk options in the Quarto style (#|). This tripped us up a bit; see GitHub Actions.\nMove chapters listing out of _bookdown.yml and into _quarto.yml.\nAdd page footer to _quarto.yml.\nHere’s what ours looked like when we finished the steps above (_quarto.yml).\n\n\n\n\n\n\n_quarto.yml contents\n\n\n\n\n\n\n\nFaylab Lab Manual\n\n\n\n\n\nChange insertion of images from html style to Quarto style. (Note Quarto calls them “figures”, not “images”.) The following snippet will insert the GitHub octocat logo in a page:\n![](https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png){fig-align=\"left\" width=\"35px\"}\nChange all filename extensions .Rmd -&gt; .qmd (you could Preview after this change and see that the book looks the same). Note that Quarto works with .Rmd files just as well as it does .qmd, so this change is not urgent. In fact, if you have a lot of R code in your .Rmds (unlike the Faylab Lab Manual), there will be additional tinkering needed to make the code chunks happy.\n\n\nCitations\nThe Faylab Lab Manual cited two papers, presenting us with an opportunity to see how easy it is to add references to a Quarto book. Briefly, in the Visual Editor, Insert &gt; Citation &gt; DOI. Pasting the DOI or its full URL, we can insert the citation. This automatically creates a references.bib file and adds the full citations at the bottom of the chapter page (watch demo). In July 2022, we had to manually add a ## References heading, but this may not be necessary in future Quarto updates.\n\n\n\n\n\n\nInsert citation via its DOI using RStudio Visual Editor\n\n\n\n\n\n\n\n\n\n\nPublishing notes\nIf the book’s output is strictly html, there’s no need to specify output-dir in _quarto.yml. The output directory default is _book/, which is what we’d like. If we wanted other types of output like like PDF or EPUB, etc. those single file outputs are also written to the output-dir (Quarto docs).\nIf you currently have a docs/ folder, delete it.\nUpdate .gitignore to ignore _book/. At the same time, we have it ignore caches and a .quarto file:\n/.quarto/\n*_cache/\n_book/\nOnce all is settled, delete _output.yml.\nOnce the Openscapes fork was fully reviewed, we made a pull request from that to the main branch of the book’s repo. Once that was merged, we set up GitHub Actions to render the book. (TODO: instructions for GitHub Actions)\n\n\nGitHub Actions\nThis book was mostly prose and screenshots without any R code. This made the conversion from RMarkdown to Quarto likely more straightforward than if you also needed to adjust code chunk options in the quarto style (#|). Our initial GitHub Action to render the converted Faylab Lab Manual failed because we had a piece of R code - even though the code was commented out! This was resolved when we deleted the line."
  },
  {
    "objectID": "transition-from-rmarkdown.html#distill-to-quarto",
    "href": "transition-from-rmarkdown.html#distill-to-quarto",
    "title": "Transition from RMarkdown",
    "section": "Distill to quarto",
    "text": "Distill to quarto\nWe transitioned our events site from distill to quarto in May 2022 (github view before and after). We followed excellent notes and examples from Nick Tierney and Danielle Navarro.\nAfter we had changed all the files, the Build tab in the RStudio IDE still showed “Build website” rather then “Render Website” and “Preview Website”, and would error when we pushed them (because that button was expecting a distill site, not a quarto site). To fix this, we updated the .Rproj file. Clicking on the .Rproj file in the RStudio IDE will open a dialog box where you can click things you want (you can also open these in a text editor or from the GitHub website to see the actual text). To fix this situation with the Build tab: Project Options &gt; Build Tools &gt; Project Build Tools &gt; None.\nLooking at files /posts/_metadata.yml and _quarto.yml helps see where things are defined. For example, to make event post citations appear, we added citation: true to /posts/_metadata.yml and in _quarto.yml under the website key we set site-url: https://openscapes.github.io/events. We deleted footer.html used with distill because footer is now defined in quarto.yml.\n\nPublishing notes\n\nBackground: Our distill site had been set up to output to a docs folder, and had GitHub Settings &gt; Pages set to look there rather gh-pages branch. (Julie note: this was a new-to-me capability when we set up the events distill site in Spring 2021 so I had forgotten that was an option). We’ve inititally kept this same set-up for now with our events page in _quarto.yml: output-dir: docs. However, this is sub-optimal; better to not have to commit and push these files but to instead have a GitHub Action generate them upon a commit. So the following is what we did -\n\nDon’t specify output-dir in _quarto.yml. The output directory default is _site/, which is what we’d like.\nIf you currently have a docs/ folder (like we did as we were experimenting), delete it.\nUpdate .gitignore to ignore _site/. At the same time, we have it ignore caches and a .quarto file:\n/.quarto/\n*_cache/\n_site/\nPush these changes, merge into main.\nOn GitHub.com, in your repo, set up GitHub publishing\nFollow instructions from the explore and setup chapter."
  },
  {
    "objectID": "transition-from-rmarkdown.html#troubleshooting",
    "href": "transition-from-rmarkdown.html#troubleshooting",
    "title": "Transition from RMarkdown",
    "section": "Troubleshooting",
    "text": "Troubleshooting\n\nGitHub Action fails, says you need RMarkdown but you don’t have R code!\nAnd you changed all .Rmds to .qmds!\nYou likely have a few setup code chunks from RMarkdown, that look like this:\n{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = FALSE)\nYou can find them by opening each of your files and having a look, or use GitHub’s search for the keyword knitr"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Barefoot Ocean Partner Manual",
    "section": "",
    "text": "This is the welcome page."
  },
  {
    "objectID": "index.html#what-is-quarto",
    "href": "index.html#what-is-quarto",
    "title": "Making shareable documents with Quarto",
    "section": "What is Quarto?",
    "text": "What is Quarto?\nQuarto helps you have your ideas and your code in one place, and present it in a beautiful way.\nQuarto unifies and extends the RMarkdown ecosystem - it unifies by combining the functionality of R Markdown, bookdown, distill, xaringian, etc into a single consistent system. And it extends in several ways: all features are possible beyond R too, including Python and Javascript. It also has more “guardrails”: accessibility and inclusion are centered in the design. Quarto is for people who love RMarkdown, and it’s for people who have never used RMarkdown.\nThe ability for Quarto to streamline collaboration has been so cool and important for our NASA Openscapes project. Quarto has been a common place for us to collaborate - across R and Python languages and coding expertise."
  },
  {
    "objectID": "index.html#what-is-this-tutorial",
    "href": "index.html#what-is-this-tutorial",
    "title": "Making shareable documents with Quarto",
    "section": "What is this tutorial?",
    "text": "What is this tutorial?\nThis is a 1-hour tutorial that can be used to teach or as self-paced learning.\nWe introduce Quarto by exploring this tutorial website, and practicing the basic Quarto workflow using different tools (GitHub browser, RStudio, and Jupyter) for editing your website.\nWe’ll start off from the browser so you don’t need to install any additional software, however this approach is very limited and you will soon outgrow its capabilities. If you don’t already have a workflow to edit files and sync to GitHub from your computer, I recommend RStudio. You don’t need to know R to use RStudio, and it has powerful editor features that make for happy workflows.\nQuarto.org is the go-to place for full documentation and more tutorials!"
  },
  {
    "objectID": "index.html#example-quarto-sites",
    "href": "index.html#example-quarto-sites",
    "title": "Making shareable documents with Quarto",
    "section": "Example Quarto sites",
    "text": "Example Quarto sites\nA few Quarto websites from Openscapes - so far we have been using Quarto for documentation using Quarto and Markdown files and Jupyter Notebooks.\n\nChampions Lessons Series\nOpenscapes Approach Guide\n\n2021 NASA Cloud Hackathon\nFaylab Lab Manual\nA Quarto tip a day, by Mine Çetinkaya-Rundel"
  },
  {
    "objectID": "index.html#about",
    "href": "index.html#about",
    "title": "Making shareable documents with Quarto",
    "section": "About",
    "text": "About\nOpenscapes is about better science for future us. We help researchers reimagine data analysis, develop modern skills that are of immediate value to them, and cultivate collaborative and inclusive research teams as part of the broader global open movement.\nWe’re developing this tutorial to help folks with different levels of technical skills use Quarto for documentation and tutorial building. This tutorial was originally created for several different audiences: NASA-Openscapes researcher support engineers using Python, communications directors at organizations promoting open science who do not identify as coders, and fisheries scientists curious about transitioning from RMarkdown. We’re hoping it’s useful to folks with backgrounds as wide as these; if you find it useful or have suggestions for improvement, please let us know by clicking “Edit this page” or “Report an issue” at the upper right side of any page."
  },
  {
    "objectID": "learning-more.html",
    "href": "learning-more.html",
    "title": "Learning more",
    "section": "",
    "text": "An excellent overview: Reproducible authoring with Quarto - Mine Çetinkaya-Rundel, Feb 2022 - slides, youtube\nA Quarto tip a day in June 2022, from Mine Çetinkaya-Rundel.\n\n\n\nOpenscapes Champions Lessons Series\nOpenscapes Approach Guide\n\nNASA Earthdata Cloud Cookbook\n\nSee many more examples at the quarto gallery!\n\n\n\nAre you making onboarding documentation? Check out The Fay Lab Manual (now in Quarto!) for inspiration on structure - you could also start there and make it your own."
  },
  {
    "objectID": "explore.html",
    "href": "explore.html",
    "title": "Explore and setup",
    "section": "",
    "text": "With this tutorial, we have a working example website that we will explore together. We’ll learn a few rules and look for patterns to get an understanding of what things to do to help you start customizing and making it your own. And you can continue to use this website as a reference after the tutorial, along with Quarto documentation.\nWe’ll start our exploration online looking at the website architecture and GitHub repository. Then we’ll setup a copy for ourselves so that we can modify from a working example, which is a great way to learn something new. We’ll set it up so that any modifications (commits) will automatically be republished via GitHub Actions. Subsequent chapters will describe how to modify your repo using different tools (browser, RStudio, Jupyter)."
  },
  {
    "objectID": "explore.html#exploring-online",
    "href": "explore.html#exploring-online",
    "title": "Explore and setup",
    "section": "Exploring online",
    "text": "Exploring online\n\nThe website itself\nThis website has 5 things you can see on the left sidebar:\n\nWelcome\nExploring and setup\nQuarto workflows\nLearning more\nTransition from Rmd\n\nMost of these are pages, but you’ll see that “Quarto Workflows” has an arrow &gt;; it is a folder with additional pages inside.\n\n\nThe website’s repo\nLet’s go to this website’s GitHub repository (also called a “repo”), https://github.com/openscapes/quarto-website-tutorial. You can also click there from any page in this tutorial website by clicking the GitHub octocat icon underneath the Openscapes logo in the left navbar (click it holding command on Mac, or control on a PC to open it in a different tab in your browser).\nHave a look at the filenames. We can recognize the names of the webpages we’ve seen above, and they have red arrows marking them in the image below. You’ll see the “quarto-workflows” folder and the rest in this site are .qmd files, which are plain text Quarto files that can combine Markdown text with code. index.qmd is the home page. If you click inside “quarto-workflows” you’ll see a mix of filetypes!\n\n\n\nquarto-website-tutorial GitHub repository with files for webpages marked with red arrows\n\n\nThe _site folder has html files with names that should be familiar: they match the .qmd files we were just exploring. This folder is where Quarto stores files to build the website."
  },
  {
    "objectID": "explore.html#quarto.yml-intro",
    "href": "explore.html#quarto.yml-intro",
    "title": "Explore and setup",
    "section": "_quarto.yml intro",
    "text": "_quarto.yml intro\nThere is also a _quarto.yml file, which is the website’s configuration file. It is essentially metadata for the website that includes the order that the pages/chapters will be in. This is where you update the organization of your website: which page comes before another. If we compare side-by-side, you’ll see that the pages that appear on our website are listed there.\n\n\n\n_quarto.yml and website side-by-side\n\n\nWe’ll learn more about how to interact with _quarto.yml in Quarto Workflows."
  },
  {
    "objectID": "explore.html#fork-to-your-account",
    "href": "explore.html#fork-to-your-account",
    "title": "Explore and setup",
    "section": "Fork to your account",
    "text": "Fork to your account\nLet’s start with an existing Quarto site and copy it into your space to edit. You’ll need a free GitHub account that you create at github.com (follow this advice about choosing your username).\nFirst, choose an existing website to copy. The simplest option is to start with this site: quarto-website-tutorial.\nOther options of potential interest:\n\n2021-Cloud-Hackathon\n2022-SWOT-Ocean-Cloud-Workshop\nOpenscapes Approach-Guide\n\nNext, follow these steps to fork and setup your repo with GitHub Actions from Gavin Fay, using the repo you chose. These instructions will take ~5 minutes.\nNow you’ve got a copy of your repo of choice in your own GitHub account, and you’re set to start making your own edits. Your GitHub repo is set up with a GitHub Action that will use Quarto to rebuild and republish your site anytime you make a commit: committing will trigger the GitHub Action to rebuild and republish the book.\nNote that the GitHub Action for this book does not include R or Python so those will need to be added if your website relies on code. See https://github.com/r-lib/actions for more details and examples.\n\nDownload instead of fork\nForking might not always be the way to go - you can’t fork into the same GitHub user account or organization so if for example you want to make a copy of 2021-Cloud-Hackathon repo within the same NASA-Openscapes GitHub Organization, you’ll need to download instead of fork. In this case, follow these steps to download and copy into a new repository, and set up the GitHub Action and the gh-pages branch for publishing, separately.\n\nDownload github repo files\nNavigate to https://github.com/openscapes/quarto-website-tutorial (or any other quarto site repo of choice). Click the green “Code” button and select “Download ZIP”. When it downloads on your computer, unzip the files.\n\n\nCreate a new GitHub repo\nNavigate to your GitHub account or organization, and create a new repository, naming it what you’d like. You’ll need a free GitHub account that you create at github.com (follow this advice about choosing your username). When you’re logged in, github.com will show a green button that says “New” which you’ll also see as you navigate to your username’s repository page.\n\n\nAdd original site files\nIf you’re comfortable cloning the new repository and copying files into it locally before committing and pushing back to GitHub, that is preferable to the GitHub file uploader, which does have limitations with complex repos. The uploader does not allow upload of folders, so some manual work would be required.\nTo use the GitHub file uploader, click the button next to the green “Code” button that says “Add file”. Add file &gt; Upload files. Then, on your computer, select all the files in unzipped folder (command-A or control-A), and drag them to the GitHub uploader page. Scroll down to write a commit message, which effectively saves your files when you’re working in the browser."
  },
  {
    "objectID": "explore.html#setup-github-action",
    "href": "explore.html#setup-github-action",
    "title": "Explore and setup",
    "section": "Set up GitHub publishing",
    "text": "Set up GitHub publishing\nIf you’ve used the ‘Fork to your account approach’ above, your website is all set!\nIf you’ve set up your repo by using the ‘Download github repo files’ approach above, you’ll need to set up GitHub publishing separately. We’ll do this in a few steps: we’ll set up a GitHub Action within your repo, and create a gh-pages branch.\nFirst, the GitHub Action. Go back to your main view of your GitHub repository by clicking on the name of your repository at the top-left (the url in your browser window should say https://github.com/username/repo-name).\nNext to the green code button, click Add file &gt; Create new file. Name it exactly this: .github/workflows/quarto-publish.yml . In detail: start by typing the . with github and when you type the / it will give you a new text box to type workflows (plural!), then another /, and finally, quarto-publish.yml.\nNow you’ll have an empty new file. Paste the following in this empty file - you can click on the top-right of this box to copy all the code inside this code box:\non:\n  push:\n    branches: main\n\nname: Render and Publish\n\njobs:\n  build-deploy:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Check out repository\n        uses: actions/checkout@v2 \n        \n      - name: Set up Quarto\n        uses: quarto-dev/quarto-actions/setup@v2\n        with:\n          # To install LaTeX to build PDF book \n          tinytex: true \n          # uncomment below and fill to pin a version\n          # version: 0.9.600\n      \n      # add software dependencies here\n\n      - name: Publish to GitHub Pages (and render)\n        uses: quarto-dev/quarto-actions/publish@v2\n        with:\n          target: gh-pages\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }} # this secret is always available for github actions\nCommit this to save your new quarto-publish.yml file. This is your GitHub Action.\nFinally, from your main repo page, click Settings &gt; Actions &gt; General. Under ‘Workflow permissions’, select ‘Read and write permissions’. Save.\nNext, we’ll create a new gh-pages branch. Go back to the main view of your GitHub repository. On the far left from the green “Code” button, click the button that says “main”. In the pull-down menu, type gh-pages - all lowercase, with a hyphen. Click the bold text that says “Create branch: gh-pages from main”.\nNow click on the Settings tab in the top right of your repository. On the left sidebar, click Pages. At the top of Pages under “Source”, select gh-pages root, and press Save (may already be saved by default).\nTo view your published website, at your main repository page, on the right side, click the gear-icon, select ‘Use your GitHub Pages website’."
  },
  {
    "objectID": "explore.html#confirm",
    "href": "explore.html#confirm",
    "title": "Explore and setup",
    "section": "Confirm your website is published",
    "text": "Confirm your website is published\nTo confirm that your website is published, go back to your main repository page. You’ll now see an orange dot showing that the GitHub Action is beginning to publish the page.\n\n\n\nOur repo with orange dot indicating in-progress GitHub Action build\n\n\nIf you do not see this orange dot, you can re-run the GitHub Action (on the main repo page, click Actions &gt; select the workflow you want to re-run &gt; click the ‘Re-run all jobs’ button.\nWhen your orange do becomes a green check, you can go inspect your published site at “https://username.github.io/your-repo). For example: https://openscapes.github.io/quarto-website-tutorial.\n\n\n\nOur repo with green check indicating successful GitHub Action build\n\n\nIt can take some time for the site to deploy, so don’t worry if you don’t see it right away."
  },
  {
    "objectID": "explore.html#renaming-your-repo",
    "href": "explore.html#renaming-your-repo",
    "title": "Explore and setup",
    "section": "Renaming your repo",
    "text": "Renaming your repo\nIf you’d like to rename your repo, go to Settings and the option to rename is on the top of the main settings page."
  },
  {
    "objectID": "explore.html#onward",
    "href": "explore.html#onward",
    "title": "Explore and setup",
    "section": "Onward!",
    "text": "Onward!\nNow you are ready to start editing and publishing! The next chapter describes how starting off from the browser, using Markdown."
  },
  {
    "objectID": "quarto-workflows/browser.html",
    "href": "quarto-workflows/browser.html",
    "title": "From the Browser",
    "section": "",
    "text": "A workflow from the browser if good for getting started (since you do not need to install additional software) and for making small contributions, but is definitely limited. Once you feel comfortable here, you can move to a different setup.\nHere’s an example of editing content on an existing page."
  },
  {
    "objectID": "quarto-workflows/browser.html#edit-content-on-an-existing-page",
    "href": "quarto-workflows/browser.html#edit-content-on-an-existing-page",
    "title": "From the Browser",
    "section": "Edit content on an existing page",
    "text": "Edit content on an existing page\nLet’s change the date on the home page of this website.\nIn your repository, navigate to index.md. Then, click the pencil icon in the top right to edit directly.\n\n\n\n\n\nWe are now in the “Edit file” tab of the editor, where we can make modifications. Let’s change the date to today’s date. Click the “Preview” tab to see your changes. You can even check the “Show diff” box on the right side to see the changes you’ve made.\n\n\n\n\n\nWhile you’re here, see if there are additional changes to the text you’d like to make. Maybe changing the title or author at the top, or for the main text on the home page of the website.\nOur index.md file is written in Markdown, which enables you to make simple text formatting. As you go back and forth from “Edit file” to “Preview”, notice the patterns of how the Markdown text looks when it is as source (“Edit file”) and when it is formatted (“Preview”). For example, in Markdown, you can make text as a header with # symbols, bold or italic with * symbols, and hyperlinks with [](). Notice that spacing is important: for example, there are carriage returns (when you hit the “return” key) before any bullet points. You can learn the short list of Markdown rules here: https://quarto.org/docs/authoring/markdown-basics."
  },
  {
    "objectID": "quarto-workflows/browser.html#commit-and-publish",
    "href": "quarto-workflows/browser.html#commit-and-publish",
    "title": "From the Browser",
    "section": "Commit and publish",
    "text": "Commit and publish\nCommit your changes by scrolling to the bottom of the page and writing a commit message - a note to yourself and others about what changes you made. Write your commit message and then click the green “Commit changes” button.\n\n\n\n\n\nNow, click back to the main page of your GitHub repository. You should see the orange dot confirming your website is published. You’ll have to wait for the GitHub Action to tell quarto to build your site for you to see the update, but it will be there!"
  },
  {
    "objectID": "quarto-workflows/browser.html#limitations",
    "href": "quarto-workflows/browser.html#limitations",
    "title": "From the Browser",
    "section": "Limitations",
    "text": "Limitations\nWhile awesome that we can edit using GitHub directly from the browser, there are obvious limitations. One is that to see your edits show up in your book, you have to publish using the GitHub Action. This is slow. Another limitation is that we can only work on one file at a time and commit them each separately, which also is slow. Using additional software can make things much better, as we explore in subsequent chapters."
  },
  {
    "objectID": "quarto-workflows/jupyter.html",
    "href": "quarto-workflows/jupyter.html",
    "title": "From Jupyter",
    "section": "",
    "text": "You can interact with Quarto through JupyterLab or JupyterHub. Your Jupyter setup will involve .ipynb notebooks and the command line. Quarto’s JupyterLab tutorials has great instructions on getting started with JupyterLab, including computations and authoring.\nHere we will demonstrate how to work with this Quarto tutorial site in JupyterHub and add a Jupyter Notebook (.ipynb file). This example uses the NASA-Openscapes JupyterHub that already has all python environments as well as Quarto installed."
  },
  {
    "objectID": "quarto-workflows/jupyter.html#setup",
    "href": "quarto-workflows/jupyter.html#setup",
    "title": "From Jupyter",
    "section": "Setup",
    "text": "Setup\n\nJupyterHub\nOur JupyterHub is already setup with python environments as well as Quarto (through nasa-openscapes/corn), so there is no further installation required.\n\n\nClone your repo\nYou’ll start by cloning your repository into JupyterHub. Do this by opening a terminal (File &gt; New &gt; Terminal). In the Terminal, git clone your repository and cd into it:\ngit clone https://github.com/openscapes/quarto-website-tutorial\ncd quarto-website-tutorial\n\n\nInstall Quarto\nNot needed - Quarto is already installed on the NASA-Openscapes JupyterHub! But to install elsewhere you would do so from https://quarto.org/docs/get-started/.\nQuarto is a Command Line Interface (CLI), like git. Once download is complete, follow the installation prompts on your computer like you do for other software. You won’t see an application to click on when it is installed.\nNote for Mac users: If you do not have administrative privileges, please select “Install for me only” during the Destination Selection installation step (you will first click on “Change Install Location” at the Installation Type step).\nYou can check to confirm that Quarto is installed properly from the command line:\nquarto check install\n\n\n\n\n\n\nAdditional checks\n\n\n\n\n\nYou can also run:\n\nquarto check knitr to locate R, verify we have the rmarkdown package, and do a basic render\nquarto check jupyter to locate Python, verify we have Jupyter, and do a basic render\nquarto check to run all of these checks together\n\n\n\n\n\n\n\n\n\n\nHistorical aside: Install Quarto in a docker container\n\n\n\n\n\nIn Summer 2021 some NASA Mentors trying to install quarto locally was not an option, but they were able to install it inside a container using the following Dockerfile:\n#| fold: true\n#| summary: \"Show the Dockerfile\"\n\n##############################\n# This Dockerfile installs quarto and then runs quarto serve against the\n# internal /home/quarto/to_serve.\n#\n# BUILD\n# -----\n# To build this container, run\n#\n#     docker build -t quarto_serve .\n#\n# Add the --no-cache option to force docker to build fresh and get the most\n# recent version of quarto.\n#\n#\n# RUN\n# ---\n# 1. Find the directory you want quarto to serve. Let's call this /PATH/TO/earthdata-cloud-cookbook.\n# 2. Run docker:\n#\n#     docker run --rm -it -p 4848:4848 -v /PATH/TO/earthdata-cloud-cookbook:/home/quarto/to_serve quarto_serve\n#\n# 3. Open your browser and go to http://127.0.0.1:4848/\n#\n##############################\n\nFROM ubuntu:hirsute\n\n######\n# Install some command line tools we'll need\n######\nRUN apt-get update\nRUN apt-get -y install wget\nRUN apt-get -y install gdebi-core\nRUN apt-get -y install git\n\n\n######\n# Install quarto (https://quarto.org/)\n######\n\n# This is a quick and dirty way of getting the newest version number from\n# https://github.com/quarto-dev/quarto-cli/releases/latest. What's happening is\n# we're pulling the version number out of the redirect URL. This will end up\n# with QVER set to something like 0.2.11.\nRUN QVER=`wget --max-redirect 0 https://github.com/quarto-dev/quarto-cli/releases/latest 2&gt;&1 | grep \"Location\" | sed 's/L.*tag\\/v//' | sed 's/ .*//'` \\\n    && wget -O quarto.deb \"https://github.com/quarto-dev/quarto-cli/releases/download/v$QVER/quarto-$QVER-amd64.deb\"\nRUN gdebi -n quarto.deb\n\n# Run this to make sure quarto installed correctly\nRUN quarto check install\n\n\n######\n# Create a non-root user called quarto\n######\nRUN useradd -ms /bin/bash quarto\nUSER quarto\nRUN mkdir /home/quarto/to_serve\nWORKDIR /home/quarto/to_serve\n\n\n######\n# Start quarto serve\n######\n\nCMD quarto serve --no-browse --host 0.0.0.0 --port 4848"
  },
  {
    "objectID": "quarto-workflows/jupyter.html#quarto-preview",
    "href": "quarto-workflows/jupyter.html#quarto-preview",
    "title": "From Jupyter",
    "section": "Quarto preview",
    "text": "Quarto preview\nLet’s start off by previewing our quarto site locally. In Terminal, type quarto preview, which will provide a URL with a preview of our site!\nquarto preview\n# Preparing to preview\n# Watching files for changes\n# Browse at https://openscapes.2i2c.cloud/user/jules32/proxy/4593/\nCopy this URL into another browser window; and arrange them so you can see them both. I make a bit more space in Jupyter by collapsing the left file menu by clicking on the file icon at the top of the left sidebar.\n\n\n\n\n\n\nMake a small change and preview it\nNow we’ll be able to see live changes in the preview as we edit in our .md files. Let’s try it: Change the date in index.md by opening it from the file directory. Change to today’s date, and save. Your preview window will refresh automatically! If it does not, you can also refresh the page manually. The refreshed previewed site will now display your changes!"
  },
  {
    "objectID": "quarto-workflows/jupyter.html#create-a-new-.ipynb-page",
    "href": "quarto-workflows/jupyter.html#create-a-new-.ipynb-page",
    "title": "From Jupyter",
    "section": "Create a new .ipynb page",
    "text": "Create a new .ipynb page\nLet’s add a new page to our site. Instead of an .md file like the others, let’s add a .ipynb file.\nFile &gt; New &gt; Notebook. Accept the default kernel by clicking Select.\n\nFirst chunk: raw yaml\nBy default, this Notebook will give us a first chunk that is code. Let’s change it to raw so that we can write our yaml at the top.\n\n\n\n\n\nIn our Raw code chunk, let’s write the title of this document. We need three dashes --- on separate lines preceding and following the title:, which you can name as you’d like.\n---\ntitle: Python Example\n---\n\n\nSecond chunk: Markdown\nLet’s add a new chunk that is Markdown so we can write some description of what this page will be.\nClick the + symbol at the top of the document, and this will add a new chunk, which by default again is a Code chunk. Change it to a Markdown Chunk following the steps we did above when switching to Raw.\nHere, write a little bit of text in Markdown. Since your title is effectively a level-1 header, avoid using level-1 headers in the rest of your document. Here is some example text I wrote:\n## Introduction\n\nThis example has some Python code that will be a part of our Quarto site.\n\n\nThird chunk: Code\nNow let’s create a new chunk with the default Code setting.\nPaste the following code (or write some of your own to test):\n#| label: fig-polar\n#| fig-cap: \"A line plot on a polar axis\"\nimport numpy as np\nimport matplotlib.pyplot as plt\nr = np.arange(0, 2, 0.01)\ntheta = 2 * np.pi * r\nfig, ax = plt.subplots(\n  subplot_kw = {'projection': 'polar'} \n)\nax.plot(theta, r)\nax.set_rticks([0.5, 1, 1.5, 2])\nax.grid(True)\nplt.show()\nNow, go ahead and execute this code chunk like you normally would, by clicking the cursor in a code block and clicking the sideways “play” triangle to run the selected cells (and advance to the next cell). This code produces a plot.\nNote that the code runs as it normally would; the code options in the comments are just comments.\n\n\nSave your file\nSave your document - I’ll call mine python-example.ipynb in the main repository."
  },
  {
    "objectID": "quarto-workflows/jupyter.html#update-_quarto.yml",
    "href": "quarto-workflows/jupyter.html#update-_quarto.yml",
    "title": "From Jupyter",
    "section": "Update _quarto.yml",
    "text": "Update _quarto.yml\nNow we’ll add python-example.ipynb to our _quarto.yml file; this is where we register of all files to include in our site. Let’s add it after the section called “Basic Workflows”.\nOpen _quarto.yml by clicking on it from the file directory.\nScroll down to review the current contents in the sidebar: section. It’s there we see all the file arrangement that we see in the previewed site.\nAdd - python-example.ipynb to line 46, making sure that your indentation aligns with the other pages.\n\n\n\n\n\nYou’ll see that our new page shows up in our Preview, and the code is executed since we did that in the Jupyter Notebook itself. By default, Quarto will not execute code chunks since your computations will likely become more complex and you will want to control when they are executed (or “run”).\nSince Quarto is still previewing our website and the python-example.ipynb, the plot also displays in the notebook after the code is run and the file is saved, as shown below.\n\n\n\n\n\nSo, your normal workflow for creating and running code blocks in your Jupyter Notebook is the same one you’ll use as Quarto displays the preview."
  },
  {
    "objectID": "quarto-workflows/jupyter.html#quarto-render",
    "href": "quarto-workflows/jupyter.html#quarto-render",
    "title": "From Jupyter",
    "section": "Quarto render",
    "text": "Quarto render\nSo far we have used Quarto preview to view our website as we develop it. Quarto render will build the html elements of the website that we can see when we preview. Rendering will format the markdown text and code nicely as a website (or however is indicated in the _quarto.yml).\nBy default, Quarto render does not execute code in a Jupyter notebook. It will never run .ipynb files unless you tell it to.\n\nRender whole notebook\nIf you would like it to specifically execute code in a Jupyter notebook, you can do so in Terminal.\nOur Terminal is still busy previewing our website, so let’s open a new Terminal.\nFile &gt; New &gt; Terminal. Then type:\ncd quarto-website-tutorial\nquarto render python-example.ipynb --execute"
  },
  {
    "objectID": "quarto-workflows/jupyter.html#authoring-tips",
    "href": "quarto-workflows/jupyter.html#authoring-tips",
    "title": "From Jupyter",
    "section": "Authoring tips",
    "text": "Authoring tips\nQuarto.org has details about authoring, including specific instructions about authoring in Jupyter: quarto.org/docs/reference/cells/cells-jupyter."
  },
  {
    "objectID": "quarto-workflows/jupyter.html#commit-and-push",
    "href": "quarto-workflows/jupyter.html#commit-and-push",
    "title": "From Jupyter",
    "section": "Commit and push!",
    "text": "Commit and push!\nCommitting and pushing will make the changes you see locally live on your website (using the GitHub Action we set up earlier)."
  },
  {
    "objectID": "quarto-workflows/jupyter.html#troubleshooting",
    "href": "quarto-workflows/jupyter.html#troubleshooting",
    "title": "From Jupyter",
    "section": "Troubleshooting",
    "text": "Troubleshooting\n\nMy changes don’t show up in preview\nMake sure you’ve saved your file! There might be a slight delay depending on your JupyterHub/Lab setup.\n\n\nQuarto render hangs / does not complete\nCheck the specific notebook, are there any `—` throughout to denote line breaks rather than yaml? They might be causing the issue; consider deleting those.\nAlso check how long the first raw cell is. Are there level-1 headers (#)? Try removing them."
  },
  {
    "objectID": "quarto-workflows/index.html",
    "href": "quarto-workflows/index.html",
    "title": "Quarto workflows",
    "section": "",
    "text": "How do you work in Quarto? You can use whichever tool you’re comfortable with (RStudio, Jupyter, GitHub, VS Code, etc). Developing your quarto site will have the same basic workflow, no matter which tool you use. It is very iterative, and each is explored more below.\n\nAuthoring: write text, code, images, etc in a file. Supported files include .md, .Rmd, .qmd, .ipynb…\nUpdate _quarto.yml as needed (for example, if you’ve created a new file you’d like included in your site)\nRender individual files and/or the whole website\nRepeat, repeat, repeat\nCommit and push your website to GitHub, your updates will publish automatically!\nRepeat all of the above to make the website as you’d like!\n\nNote: if editing from your internet browser we won’t render in Step 3. That step will not be separate, but combined with Step 5, which will only require a commit, not a push."
  },
  {
    "objectID": "quarto-workflows/index.html#authoring",
    "href": "quarto-workflows/index.html#authoring",
    "title": "Quarto workflows",
    "section": "Authoring",
    "text": "Authoring\nAs an author, you have a lot of options of how your text will be formatted, arranged, and interlinked. You will be writing in Markdown, which is a lightweight text formatting language. The Quarto documentation about authoring introduces markdown-basics that will get you started. Also see Mine Çetinkaya-Rundel’s A Quarto tip a day.\nEach page of our site has a similar first few lines - this YAML, like we saw in our _quarto.yml and it is indicated by two sets of 3 dashes --- :\n---\ntitle: My title\n---\nYou’re able to add more features to individual pages by including it in the YAML, which for the most part here only includes a title. See Quarto excecution options for more information of what you can include in the YAML."
  },
  {
    "objectID": "quarto-workflows/index.html#update-_quarto.yml",
    "href": "quarto-workflows/index.html#update-_quarto.yml",
    "title": "Quarto workflows",
    "section": "Update _quarto.yml",
    "text": "Update _quarto.yml\nLet’s have a closer look at the _quarto.yml file.\nThis type of file (.yml or .yaml) is written in YAML (“Yet Another Markup Language”). You’ll be able to shift the arrangement of webpages by reordering/adding/deleting them in the _quarto.yml file following the patterns you see in this example.\n\n\n\n_quarto.yml and website side-by-side\n\n\nNotice that there are multiple ways in the _quarto.yml for you to include a file in your website. For example, in the above image, the “First Observations” we see in the left sidebar of the published website (right image) is represented in _quarto.yml (left image) over two lines, with line 36 indicating the file reference and line 37 indicating the text to show up in the left sidebar. However, “From RStudio” is only represented in one line of _quarto.yml, on line 43. This represents two strategies for including a file in your website. By default, the title of a specified file will show up in the website’s sidebar, which is what is happening with the “From RStudio” example. If you would like more control over what is written in the sidebar vs the title of your files, then the approach we took with “First Observations” is what you’ll want to do: you’ll see that only “First Observations” shows up in the sidebar as we specified in _quarto.yml, but the page’s title says “First Observations & Setup” (which in our preference was too long for the sidebar).\n\n\n\n\n\n\nNote\n\n\n\nAs you modify _quarto.yml, the most important thing to know is that spacing matters. Pay attention to whether text is indented by one, two, four, or other spaces, and make sure you follow it; if your site is not looking as expected it is likely a silent error in your YAML. Some text editors like RStudio provide debugging support for YAML and are highly recommended to save you time and heartache."
  },
  {
    "objectID": "quarto-workflows/index.html#install-quarto",
    "href": "quarto-workflows/index.html#install-quarto",
    "title": "Quarto workflows",
    "section": "Install Quarto",
    "text": "Install Quarto\nhttps://quarto.org/docs/get-started/ describes how to install Quarto, which will depend on your operating system. We’ll walk through installation for each tool in the next chapters."
  },
  {
    "objectID": "quarto-workflows/rstudio.html",
    "href": "quarto-workflows/rstudio.html",
    "title": "From RStudio",
    "section": "",
    "text": "The RStudio software (called an IDE, integrated development environment) is an excellent way to edit files and interface with GitHub. Plus, as it is made by the same folks who make Quarto, it has many integrated features for streamlining your workflow with Quarto, including how it previews your edits and provides debugging support for yaml! Quarto's RStudio tutorials has great instructions on getting started with RStudio, including computations and authoring.\nHere is what you’ll need to do to set up and use RStudio with Quarto."
  },
  {
    "objectID": "quarto-workflows/rstudio.html#setup",
    "href": "quarto-workflows/rstudio.html#setup",
    "title": "From RStudio",
    "section": "Setup",
    "text": "Setup\n\nRStudio and GitHub\nFor a workflow with RStudio and GitHub on your local computer, you will need four things:\n\nR\nRStudio\nGit\nGitHub\n\nFollow the UCSB MEDS Installation Guide for detailed instructions on how to create accounts, download, install, and configure on Mac and Windows. This takes about 20 minutes. (For an even more detailed walk-through, see Allison Horst’s ESM 206 Google Doc).\n\n\nClone your repo\nYou’ll start by cloning your repository into RStudio.\nFile &gt; New Project &gt; Version Control &gt; Git &gt; paste your repository name.\nR for Excel Users: Clone your repository using RStudio has detailed instructions and screenshots of these steps.\n\n\nInstall Quarto\nNext, you’ll install Quarto: https://quarto.org/docs/get-started/. After downloading, follow the installation wizard on your computer. When it is complete, you won’t see an application or any new software, but it is now available to RStudio (as well as all other applications on your computer, including the command line).\n\n\nRStudio orientation\nNow let’s take a moment to get oriented. This is an RStudio project, which is indicated in the top-right. The bottom right pane shows all the files in your project; everything we’ve cloned from GitHub. We can open any RStudio project by opening its .Rproj file, or from RStudio File &gt; Open Project ….\n\n\n\nRStudio IDE highlighting the project name and files pane\n\n\n\n\nVisual Editor\nThe RStudio Visual Editor is quite new and has features that improve your writing experience. Working in the Visual Editor feels a bit like working in a Google Doc.\nHere’s an example showing the same file in the original Source Editor with content in markdown format and in the Visual Editor with content that looks more like it will appear in a live site. You can switch freely between these modes.\n\n\n\n\n\n\nRStudio IDE highlighting the Source Editor\n\n\n\n\n\n\n\nRStudio IDE highlighting the Visual Editor\n\n\n\n\n\nAlready have some content formatted in a Google Doc? You can copy-paste it into the Visual Editor and most formatting will be retained.\nThe editing bar provides familiar point and click access to text formatting options like bulleted or numbered lists.\n\n\n\nRStudio IDE highlighting the point and click editing bar\n\n\n\nKeyboard shortcuts\nThe Visual Editor also lets you use many keyboard shortcuts that might be familiar for adding boldface (command-b), italics (command-i), or headers. On a Mac, option-command-2 will make a level 2 header. Try it with option-command-1, or option-command-0 for normal text!\n\n\nInsert an image or figure\nTo insert an image (called a figure in Quarto), click the image icon. This brings up a window in which we can select the image, set its alignment, give it a caption and alt text, hyperlink it, or edit other metadata.\n\n\n\nInsert image or figure using the Visual Editor\n\n\nOnce an image is added, clicking on that image gives us editing options. We can resize it dynamically by clicking in the image and dragging a corner or side to resize. When an image is selected, its dimensions are displayed for editing. Clicking on the gray ellipsis to the right of the dimensions opens the pop-up window to access more metadata edits.\n\n\nInsert a table\nSimilar to adding an image, to insert a table, we click the Table dropdown."
  },
  {
    "objectID": "quarto-workflows/rstudio.html#quarto-render",
    "href": "quarto-workflows/rstudio.html#quarto-render",
    "title": "From RStudio",
    "section": "Quarto render",
    "text": "Quarto render\nIn the Build tab in the top-right pane, click “Render Website”. This will build the .html files and preview your website. It’s equivalent to “knitting” in RMarkdown.\nNote that you can also click “Preview Website”. With “Render Website” in RStudio, Quarto is able to render and preview in one step.\nIf you’d ever like to stop the preview, in the bottom-left, click on the Jobs tab and then the red Stop button.\n\nMake a small change and render it\nClick on index.md. This will open this markdown file in a fourth pane; the editor pane. Make a small change, for example change to today’s date on Line 4. Then, save your file; there is a disc icon at the top of the file.\nThen, render this file: press “Render” which is to the right of the disc icon that saves the file. This will render only this single file, as opposed to rerendering the whole website like when we clicked “Render Website” in the top right pane. Checking Render on Save (between the disc icon and the Render button) is a great strategy for doing this in one step."
  },
  {
    "objectID": "quarto-workflows/rstudio.html#create-a-new-.rmd-page",
    "href": "quarto-workflows/rstudio.html#create-a-new-.rmd-page",
    "title": "From RStudio",
    "section": "Create a new .Rmd page",
    "text": "Create a new .Rmd page\nNew &gt; RMarkdown document &gt; OK\nThe starter RMarkdown document has some R code inside: it displays a summary of the cars dataset that is pre-loaded into R (summary(cars)) and plots the pressure data that is also pre-loaded (plot(pressure)).\nSave this document as r-example.rmd."
  },
  {
    "objectID": "quarto-workflows/rstudio.html#update-_quarto.yml",
    "href": "quarto-workflows/rstudio.html#update-_quarto.yml",
    "title": "From RStudio",
    "section": "Update _quarto.yml",
    "text": "Update _quarto.yml\nNow we’ll add r-example.rmd to our _quarto.yml file; this is where we register all files to include in our site. Let’s add it after the section called “Quarto Workflows”.\nOpen _quarto.yml by clicking on it from the file directory.\nScroll down to review the current contents in the sidebar: section under contents:. It’s there we see all the file arrangement that we see in the previewed site.\nAdd - r-example.rmd in its own line, making sure that your indentation aligns with the other pages.\nFrom the Build tab, clicking Preview Website will recreate your website!"
  },
  {
    "objectID": "quarto-workflows/rstudio.html#authoring-tips",
    "href": "quarto-workflows/rstudio.html#authoring-tips",
    "title": "From RStudio",
    "section": "Authoring tips",
    "text": "Authoring tips\nChecking “Render on Save” is really helpful when iterating quickly on a document.\nIf the document is very code-heavy, consider using freeze that will not run the code each time.\nQuarto.org has details about authoring, including specific instructions about authoring in RStudio."
  },
  {
    "objectID": "quarto-workflows/rstudio.html#commit-and-push",
    "href": "quarto-workflows/rstudio.html#commit-and-push",
    "title": "From RStudio",
    "section": "Commit and push!",
    "text": "Commit and push!\nCommitting and pushing will make the changes you see locally live on your website (using the GitHub Action we set up earlier)."
  },
  {
    "objectID": "quarto-workflows/rstudio.html#troubleshooting",
    "href": "quarto-workflows/rstudio.html#troubleshooting",
    "title": "From RStudio",
    "section": "Troubleshooting",
    "text": "Troubleshooting\nIf you have trouble rendering your website after for example changing the extenstion of a file from .md to .qmd, refreshing your RStudio often helps. Do this by clicking the project name at the upper right of the RStudio window (in this case, quarto-website-tutorial), and underneath the “close project” section, click the same name of your project: quarto-website-tutorial. This will relaunch your whole project afresh."
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "Barefoot Ocean Partner Manual",
    "section": "",
    "text": "This is the welcome page."
  },
  {
    "objectID": "learning-more.html#learn-more",
    "href": "learning-more.html#learn-more",
    "title": "Learning more",
    "section": "",
    "text": "An excellent overview: Reproducible authoring with Quarto - Mine Çetinkaya-Rundel, Feb 2022 - slides, youtube\nA Quarto tip a day in June 2022, from Mine Çetinkaya-Rundel.\n\n\n\nOpenscapes Champions Lessons Series\nOpenscapes Approach Guide\n\nNASA Earthdata Cloud Cookbook\n\nSee many more examples at the quarto gallery!\n\n\n\nAre you making onboarding documentation? Check out The Fay Lab Manual (now in Quarto!) for inspiration on structure - you could also start there and make it your own."
  },
  {
    "objectID": "quarto-workflows/index.html#basic-workflow",
    "href": "quarto-workflows/index.html#basic-workflow",
    "title": "Quarto workflows",
    "section": "",
    "text": "How do you work in Quarto? You can use whichever tool you’re comfortable with (RStudio, Jupyter, GitHub, VS Code, etc). Developing your quarto site will have the same basic workflow, no matter which tool you use. It is very iterative, and each is explored more below.\n\nAuthoring: write text, code, images, etc in a file. Supported files include .md, .Rmd, .qmd, .ipynb…\nUpdate _quarto.yml as needed (for example, if you’ve created a new file you’d like included in your site)\nRender individual files and/or the whole website\nRepeat, repeat, repeat\nCommit and push your website to GitHub, your updates will publish automatically!\nRepeat all of the above to make the website as you’d like!\n\nNote: if editing from your internet browser we won’t render in Step 3. That step will not be separate, but combined with Step 5, which will only require a commit, not a push."
  },
  {
    "objectID": "English-en/index.html",
    "href": "English-en/index.html",
    "title": "English",
    "section": "",
    "text": "Intro - Home Page - Quick guide? Full guide?"
  },
  {
    "objectID": "languages/en/index.html",
    "href": "languages/en/index.html",
    "title": "English",
    "section": "",
    "text": "Intro - Home Page - Quick guide? Full guide?"
  },
  {
    "objectID": "languages/en/index_en.html",
    "href": "languages/en/index_en.html",
    "title": "English",
    "section": "",
    "text": "Introduction"
  },
  {
    "objectID": "languages/en/reference_files.html#updating-reference-files-in-smartsheet",
    "href": "languages/en/reference_files.html#updating-reference-files-in-smartsheet",
    "title": "Reference Files",
    "section": "Updating reference files in Smartsheet",
    "text": "Updating reference files in Smartsheet\nAll reference files are updated in Smartsheet Dynamic View. Reference files serve as inputs for dropdown lists in KoboToolbox forms and contain data that is added to the master datasets through joins. They contain comprehensive information on the administrative levels of the fishing communities (country, province, district, village), landing sites, fishing ground, fishers, buyers, data collectors, species, management areas, gear types, and partnering organizations. The steps below outline how to update reference files with new information.\nStep 1: Create a free smartsheet account.\n\nA free account can be created at https://www.smartsheet.com/\nSelect \"Try smartsheet for free\"\n\nStep 2: Provide Barefoot Ocean the email address you used to create your smartsheet account.\n\nBarefoot Ocean will then share the reference files associated with your organization.\nTo view your reference files you will need to sign into smartsheet Dynamic View using your smartsheet credentials: https://dynamicview.smartsheet.com/login \nOnce logged in to Dynamic View (not the smartsheet app), you will see a list of reference files shared with your account (Figure 1).\n\nStep 3: Click on a reference file to make updates\n\nOnce open, you can click on each row to make edits to existing data, or click the \"New\" button in the top right corner to add new data (Figure 2). \nA details panel will appear on the right hand side where you'll input the necessary information (Figure 3; Table 1). Select \"save\" on the bottom right of the details panel when you are finished updating. You do not need to notify Barefoot Ocean when you make changes or additions to ref sheets. The will be automatically merged with the master reference files and incorporated in Kobo.\nTo leave a comment or to ask the Barefoot team any questions, select the \"Comments\" tab in the details panel. All individuals that the reference file is shared with, including the Barefoot Ocean team, will receive notification when a comment is made, so there is no need to tag any particular individual.\n\nStep 4: Respond to update requests when data is missing or incorrect, or to respond to a comment.\n\nIf there is incomplete or incorrect information that is essential for populating Kobo dropdowns or for joins, or if a comment is made in the sheet, an update request will be sent to all appropriate users, prompting them to update the information or respond to a comment (Figure 4). By default, everyone with access to your reference files will receive the update request..\nA preview of the data that needs to be updated or responded to will appear below the email message, but you will not be able to update any data directly in the email\n\nAt the bottom of the email, there is a link for \"Go to the sheet\"; however, the underlying sheet has restricted access. Please review your data or respond to the comment via Open request.\n\nClick on the \"Open Request\" button in the email message.\nA new internet browser window will open with a form-like setup for each entry (Figure 5)\nReview the BFO fields and populate the editable fields. \nClick next at the bottom of the screen to move through each entry that needs to be updated.\nTo skip an entry (e.g. if you are not sure yet which answer to pick) click \"Next\" without making a selection in the editable columns. The next entry that needs to be updated will appear.\nIf you need to exit the page or stop before all entries have been updated, your choices should be saved the next time you reopen the request. Upon opening to continue, just click \"Next\" until you find an entry that needs to be updated.\nWhen you get to the last entry, click \"Done\". A pop-up message will appear asking if you are 'Ready to submit your update?':\n\nClick \"Go Back\" if you need to review \nClick \"Submit Update\" to submit your updates.\nYour updates are automatically appended to the reference file and you can view them in Dynamic View\n\n\nIf at any time you encounter any errors, have questions, or need support for updating reference files, please contact us at barefootinfo@barefootocean.org."
  },
  {
    "objectID": "languages/en/reference_files.html",
    "href": "languages/en/reference_files.html",
    "title": "Reference Files",
    "section": "",
    "text": "&lt;iframe name=“player” src=“https://videos.hourone.ai/e?id=a0b647cf15d74b839ef6e1d44e079bd3” frameBorder=“0” allowfullscreen=“”\nallow=“accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture”&gt;\n&lt;/iframe&gt;"
  },
  {
    "objectID": "languages/en/reference_files.html#training-video",
    "href": "languages/en/reference_files.html#training-video",
    "title": "Reference Files",
    "section": "",
    "text": "&lt;iframe name=“player” src=“https://videos.hourone.ai/e?id=a0b647cf15d74b839ef6e1d44e079bd3” frameBorder=“0” allowfullscreen=“”\nallow=“accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture”&gt;\n&lt;/iframe&gt;"
  },
  {
    "objectID": "languages/en/kobo.html",
    "href": "languages/en/kobo.html",
    "title": "Data Collection",
    "section": "",
    "text": "All reference files are updated in Smartsheet Dynamic View. Reference files serve as inputs for dropdown lists in KoboToolbox forms and contain data that is added to the master datasets through joins. They contain comprehensive information on the administrative levels of the fishing communities (country, province, district, village), landing sites, fishing ground, fishers, buyers, data collectors, species, management areas, gear types, and partnering organizations. The steps below outline how to update reference files with new information.\nStep 1: Create a free smartsheet account.\n-A free account can be created at https://www.smartsheet.com/\n-Select �Try smartsheet for free�"
  },
  {
    "objectID": "languages/en/kobo.html#updating-reference-files",
    "href": "languages/en/kobo.html#updating-reference-files",
    "title": "Data Collection",
    "section": "",
    "text": "All reference files are updated in Smartsheet Dynamic View. Reference files serve as inputs for dropdown lists in KoboToolbox forms and contain data that is added to the master datasets through joins. They contain comprehensive information on the administrative levels of the fishing communities (country, province, district, village), landing sites, fishing ground, fishers, buyers, data collectors, species, management areas, gear types, and partnering organizations. The steps below outline how to update reference files with new information.\nStep 1: Create a free smartsheet account.\n-A free account can be created at https://www.smartsheet.com/\n-Select �Try smartsheet for free�"
  },
  {
    "objectID": "pages/quick_guide/quick_guide_en.html",
    "href": "pages/quick_guide/quick_guide_en.html",
    "title": "Quick Guide",
    "section": "",
    "text": "The quick guide provides step-by-step guidance to collect and validate fisheries and community data through the system developed by Barefoot Ocean. This guidance summarizes the data collection process and outlines the protocols for updating reference files and quality control tables. A full guide with further details on the Fisheries Data Collection system can be found in the Training Materials folder linked below.\nWe developed four survey forms to collect data on fisheries landings and fishing communities. Detailed survey descriptions are available in the full guide in English, Bahasa Indonesian, Cebuano, French, Tagalog, Swahili, Malagasy, Spanish, Portuguese, and Tetun translations here.\nThe Landings Monitoring Survey captures the minimum data, ideally daily or as often as possible, needed to track long-term trends in fisheries production, species composition, and catch value. This survey can help evaluate the effects of fisheries closures or other management strategies by comparing data before and after implementation. The survey is short and user-friendly to allow for more frequent and consistent data collection.\nThe Landings Profiling Survey collects detailed fisheries data on gear, effort, and size of individual fish or invertebrates alongside specialized information for specific species groups such as sex, catch quality, stylet data, and egg maturity. Catch quality of octopus includes storage methods, color, tentacle number, physical abrasions, beak quality, and skin conditions. Octopus stylet data includes sample photos and growth circumference. Egg maturity data accounts for gonad weight, color, stage, length, and line appearances in the ovary glands of female octopuses. These data complement the landings monitoring data and help partners better understand observed catch trends in fisheries production and the effects of fisheries management. The survey was designed to be performed at the beginning of involvement in a community and subsequently conducted every one to two years, before and after implementing the management strategy, or as needed to explain changes in catch observed through monitoring data.\nThe Community Profiling Survey gathers a comprehensive understanding of the socio-economic and fisheries landscape of a community. The survey is used when first engaging with a community and repeated when appropriate to document major shifts in fishing behavior, fisher perceptions, and resource management. Survey frequency will depend on project scope (i.e., when a change is expected to occur) or\nThe Fisher Household Survey captures detailed fisher household information, such as household-level perceptions of fishing-related activities, income sources, daily activities, main fish species caught, reliance on fish for food, and fishing activity. The survey is used when first engaging with a community and repeated every two to five years or after management interventions to document shifts in fishing behavior, fisher perceptions, management effectiveness, food security, trust, and gender equity.\nSteps for Using KoboToolbox Forms\n\nPrepare reference data\n\nReference data can be updated via Smartsheet and contains comprehensive information on the administrative levels of the fishing communities (country, province, district/municipality, village/community), landing sites, fishers, buyers, data collectors, species data, management areas, habitat types, gear types, and partnering organizations.\nReference data sheets are used to populate dropdown lists in the KoboToolBox survey forms and join additional data needed for analysis such as village coordinates and fisher gender.\nUpdate reference data with new species, fishers, buyers, landing sites, villages, etc. that are needed for data collection in new areas. Specific, step-by-step instructions for how to update reference files in Smartsheet can be found here.\nWhen adding a new entry, BFO automatically receives notification, so there is no need to comment to let us know you’ve added new data. Please do let us know, however, if an existing entry changes by commenting and describing the change.\nIt is critical that these files are up to date in order for data collection and analysis to run smoothly. Reference files are uploaded to kobo everyday at 9am EST.\n\nSet up the KoboToolbox Account\n\nAll surveys are administered through the use of a KoboToolBox form. Each of the survey forms can be shared with a KoboToolBox account. Set up your KoboToolbox Account here on the general server. Please reach out to courtney@barefootocean.org with account details and the forms will be shared with your account.\n\nDownload the KoboCollect App.\n\nThe Kobo forms can be accessed through the KoboCollect free Android mobile phone app or via Enketo web form.\n\nLoad forms in KoboCollect App (detailed instructions found here).\n\nOnce the app is downloaded, set up the server URL, Username, and Password, which connects your KoboCollect app to the KoboToolbox server. This allows you to download deployed forms from KoboToolbox to your mobile device and also send data collected through the app back to the server. For the URL, use the general use server URL - https://kc.kobotoolbox.org. You can access “Project Settings” by clicking the icon in the top right hand corner of the home screen. On the home screen, select “Download Form.” A list of all your deployed survey forms should appear. Press “Select All” to have all the survey forms sent to the app or select the ones you wish to have by selecting them manually. Then, click “Get Selected.” It is important that the surveys are regularly updated to ensure the latest version of the form is being used so as to not cause issues in the data pipeline down the line. While the webform is automatically updated when a new version of the survey is available, users must configure “auto-update” in the app. You can set up auto-update by going to “Settings” and “Form management”. Additional information on automatically updating surveys in the app can be found here.\n\nCollect data with the KoboToolBox survey forms\n\nCollect data by selecting “Start New Form” in the KoboCollect app. See detailed instructions on collecting data using the app here. At the end of the survey, select “Finalize.” If you want to edit the form before submitting, select “Save as draft.” If you selected “Save as draft,” your form will be sent to “Drafts.” Here, you can make edits to forms before you submit them to the final dataset. After you make changes, select “Finalize,” as mentioned above. After selecting “Finalize,” the form is automatically stored under “Ready to send.” In the current version of Kobo, you can still edit forms here. In the future, however, you will not be able to edit once they are finalized, and “Ready to send” will just be a holding place to store finalized forms until you have an internet connection to send them to the server. Select “Send selected” to send all forms to the server. Data collected using the app or web form will be cleaned and stored in a central data storage system. Raw data is backed up in the KoboToolbox database.\n\nValidate data in Smartsheet\n\nAll data that flows through the fisheries data system is validated in Smartsheet. A full step-by-step instruction guide for completing data validation can be found here.\nData is sent for validation under two scenarios; 1) new names for a fisher, buyer, data collector or species are manually added in Kobo Collect, or 2) a numeric value falls beyond established thresholds. These entries must be verified before being included in the final dataset, visualized in the dashboard, and added to the reference files.\nAny new names or flagged data are sent to the relevant quality control (QA) table in Smartsheet for field teams to validate. The quality control tables are partner-specific and can be accessed via update requests sent to your email or by visiting the Dynamic View links provided to you. Field team leads will be notified via email when data needs to be validated in the QA tables.\nValidating new names: When a new name is entered during data collection, these entries are automatically cross-referenced against the reference files to assess whether new entries might already exist in the reference files, but perhaps spelled differently. Any similar existing entries will be added to the QA table under the “ref_match” columns. Team leads can then easily verify if the “new” data is in fact already in the reference files. Team leads will complete the “validation_options” column in each QA table by selecting either new_datae, the cross-referenced data entry from the reference file (i.e. a “ref_match”), other, or remove. If “other” is selected, you must provide a name in the “other” column. If it’s a new local species name that needs to be validated, a column with the photo taken during data collection will be provided for reference.\nValidating numeric values with threshold warnings: For any flagged data entries, team leads will complete data validation in the “correct” column by selecting Y (yes, values are correct), N (no, values are not correct), or remove (data cannot be validated and should be removed from the master dataset). If no is selected, correct values for the numerator or denominator should be entered in the “correct_numerator” and “correct_denominator” columns.\nOnce the data have been verified in the QA tables, we will append new information to the reference file and provide necessary corrections to the master dataset.\n\nUpdate translations sheet\n\nTranslations for all languages are completed by editing the translations Google Sheet. If you find that a translation needs updating, please directly update the Google Sheet, highlight the updated row in yellow, and add a comment assigning the task by typing “@” or “+” followed by the email addresses alice@barefootocean.org and brittany@barefootocean.org. If new translations are needed, the Barefoot team will comment and assign the task to the country team lead.\n\nVisualize and use data\n\nAutomated analyses and visualizations will be available through standardized dashboards. Datasets will also be available through download or direct link to another database or data warehouse.\nPlease let us know if you have any questions.\nThank you!\nBarefoot Ocean Team\nBarefoot Ocean Contacts\nCourtney - courtney@barefootocean.org\nBrittany - brittany@barefootocean.org\nKatie- katie@barefootocean.org\nLaura- laura@barefootocean.org"
  },
  {
    "objectID": "pages/index/index_en.html",
    "href": "pages/index/index_en.html",
    "title": "English",
    "section": "",
    "text": "Introduction"
  },
  {
    "objectID": "pages/kobo/kobo_en.html",
    "href": "pages/kobo/kobo_en.html",
    "title": "Data Collection",
    "section": "",
    "text": "All reference files are updated in Smartsheet Dynamic View. Reference files serve as inputs for dropdown lists in KoboToolbox forms and contain data that is added to the master datasets through joins. They contain comprehensive information on the administrative levels of the fishing communities (country, province, district, village), landing sites, fishing ground, fishers, buyers, data collectors, species, management areas, gear types, and partnering organizations. The steps below outline how to update reference files with new information.\nStep 1: Create a free smartsheet account.\n-A free account can be created at https://www.smartsheet.com/\n-Select �Try smartsheet for free�"
  },
  {
    "objectID": "pages/kobo/kobo_en.html#updating-reference-files",
    "href": "pages/kobo/kobo_en.html#updating-reference-files",
    "title": "Data Collection",
    "section": "",
    "text": "All reference files are updated in Smartsheet Dynamic View. Reference files serve as inputs for dropdown lists in KoboToolbox forms and contain data that is added to the master datasets through joins. They contain comprehensive information on the administrative levels of the fishing communities (country, province, district, village), landing sites, fishing ground, fishers, buyers, data collectors, species, management areas, gear types, and partnering organizations. The steps below outline how to update reference files with new information.\nStep 1: Create a free smartsheet account.\n-A free account can be created at https://www.smartsheet.com/\n-Select �Try smartsheet for free�"
  },
  {
    "objectID": "pages/reference_files/reference_files_en.html#updating-reference-files-in-smartsheet",
    "href": "pages/reference_files/reference_files_en.html#updating-reference-files-in-smartsheet",
    "title": "Reference Files",
    "section": "Updating reference files in Smartsheet",
    "text": "Updating reference files in Smartsheet\nAll reference files are updated in Smartsheet Dynamic View. Reference files serve as inputs for dropdown lists in KoboToolbox forms and contain data that is added to the master datasets through joins. They contain comprehensive information on the administrative levels of the fishing communities (country, province, district, village), landing sites, fishing ground, fishers, buyers, data collectors, species, management areas, gear types, and partnering organizations. The steps below outline how to update reference files with new information.\nStep 1: Create a free smartsheet account.\n\nA free account can be created at https://www.smartsheet.com/\nSelect \"Try smartsheet for free\"\n\nStep 2: Provide Barefoot Ocean the email address you used to create your smartsheet account.\n\nBarefoot Ocean will then share the reference files associated with your organization.\nTo view your reference files you will need to sign into smartsheet Dynamic View using your smartsheet credentials: https://dynamicview.smartsheet.com/login \nOnce logged in to Dynamic View (not the smartsheet app), you will see a list of reference files shared with your account (Figure 1).\n\nStep 3: Click on a reference file to make updates\n\nOnce open, you can click on each row to make edits to existing data, or click the \"New\" button in the top right corner to add new data (Figure 2). \nA details panel will appear on the right hand side where you'll input the necessary information (Figure 3; Table 1). Select \"save\" on the bottom right of the details panel when you are finished updating. You do not need to notify Barefoot Ocean when you make changes or additions to ref sheets. The will be automatically merged with the master reference files and incorporated in Kobo.\nTo leave a comment or to ask the Barefoot team any questions, select the \"Comments\" tab in the details panel. All individuals that the reference file is shared with, including the Barefoot Ocean team, will receive notification when a comment is made, so there is no need to tag any particular individual.\n\nStep 4: Respond to update requests when data is missing or incorrect, or to respond to a comment.\n\nIf there is incomplete or incorrect information that is essential for populating Kobo dropdowns or for joins, or if a comment is made in the sheet, an update request will be sent to all appropriate users, prompting them to update the information or respond to a comment (Figure 4). By default, everyone with access to your reference files will receive the update request..\nA preview of the data that needs to be updated or responded to will appear below the email message, but you will not be able to update any data directly in the email\n\nAt the bottom of the email, there is a link for \"Go to the sheet\"; however, the underlying sheet has restricted access. Please review your data or respond to the comment via Open request.\n\nClick on the \"Open Request\" button in the email message.\nA new internet browser window will open with a form-like setup for each entry (Figure 5)\nReview the BFO fields and populate the editable fields. \nClick next at the bottom of the screen to move through each entry that needs to be updated.\nTo skip an entry (e.g. if you are not sure yet which answer to pick) click \"Next\" without making a selection in the editable columns. The next entry that needs to be updated will appear.\nIf you need to exit the page or stop before all entries have been updated, your choices should be saved the next time you reopen the request. Upon opening to continue, just click \"Next\" until you find an entry that needs to be updated.\nWhen you get to the last entry, click \"Done\". A pop-up message will appear asking if you are 'Ready to submit your update?':\n\nClick \"Go Back\" if you need to review \nClick \"Submit Update\" to submit your updates.\nYour updates are automatically appended to the reference file and you can view them in Dynamic View\n\n\nIf at any time you encounter any errors, have questions, or need support for updating reference files, please contact us at barefootinfo@barefootocean.org."
  },
  {
    "objectID": "pages/kobo_setup/kobo_setup_en.html",
    "href": "pages/kobo_setup/kobo_setup_en.html",
    "title": "Kobo Setup",
    "section": "",
    "text": "Download KoboCollect from the GooglePlay store.\nOpen the app, and select “Manually enter project details.” Instructions on setting up via QR code can be found here.\nSet up the server connection and enter login credentials. Use the general server: https://kc.kobotoolbox.org\nIf you already have Kobo downloaded, and want to add another account to the app, select your user icon in the top right corner of the screen. Select “Add Project.” From there, you can manually enter project details, or use a QR code.\nAfter setting up the server, select “Download form” from the home screen. A list of all survey forms shared with your account should appear.\nSelect all the survey forms shared with your account, or select the ones you wish to have by selecting them manually. Then, click “Get Selected.” Kobo will then connect to the server to fetch all forms. This requires an internet connection.\nSet up “auto-update” to ensure the surveys in the app stay up to date when changes are made (steps 8-13). If the most recent version of the survey is not being used, this will cause issues in the data pipeline and database.\nClick on your user icon in the top right corner.\nClick on settings.\nOnce there, click on “Form Management.”\nThen, click on “Blank form update mode.”\nSelect “Exactly match server.” This will ensure the survey is updated to the most recent version.\nLastly, select “Automatic update frequency” and then choose one of the frequencies.\nNavigate back to the home screen. To collect data, select “Start new form.”\nThen, select the survey form that you want to use to start collecting data.\nGo through all the questions in the survey by selecting the NEXT key.\nAt the end of the survey, select “Finalize.” If you want to edit the form before submitting, select “Save as draft.”\nIf you selected “Save as draft,” your form will be sent to “Drafts.” Here, you can make edits to forms before you submit them to the final dataset. After you make changes, select “Finalize,” like in step 17.\nAfter selecting “Finalize,” the form is automatically stored under “Ready to send.” In the current version of Kobo, you can still edit forms here. In the future, however, you will not be able to edit once they are finalized, and “Ready to send” will just be a holding place to store finalized forms until you have an internet connection to send them to the server.\nSelect “Send selected” to send all forms to the server.\nTo ensure the forms were uploaded successfully to the server, select “Sent.” These forms are now part of the final dataset."
  },
  {
    "objectID": "pages/kobo_setup/kobo_setup_en.html#kobocollect-setup-guidance",
    "href": "pages/kobo_setup/kobo_setup_en.html#kobocollect-setup-guidance",
    "title": "Kobo Setup",
    "section": "",
    "text": "Download KoboCollect from the GooglePlay store.\nOpen the app, and select “Manually enter project details.” Instructions on setting up via QR code can be found here.\nSet up the server connection and enter login credentials. Use the general server: https://kc.kobotoolbox.org\nIf you already have Kobo downloaded, and want to add another account to the app, select your user icon in the top right corner of the screen. Select “Add Project.” From there, you can manually enter project details, or use a QR code.\nAfter setting up the server, select “Download form” from the home screen. A list of all survey forms shared with your account should appear.\nSelect all the survey forms shared with your account, or select the ones you wish to have by selecting them manually. Then, click “Get Selected.” Kobo will then connect to the server to fetch all forms. This requires an internet connection.\nSet up “auto-update” to ensure the surveys in the app stay up to date when changes are made (steps 8-13). If the most recent version of the survey is not being used, this will cause issues in the data pipeline and database.\nClick on your user icon in the top right corner.\nClick on settings.\nOnce there, click on “Form Management.”\nThen, click on “Blank form update mode.”\nSelect “Exactly match server.” This will ensure the survey is updated to the most recent version.\nLastly, select “Automatic update frequency” and then choose one of the frequencies.\nNavigate back to the home screen. To collect data, select “Start new form.”\nThen, select the survey form that you want to use to start collecting data.\nGo through all the questions in the survey by selecting the NEXT key.\nAt the end of the survey, select “Finalize.” If you want to edit the form before submitting, select “Save as draft.”\nIf you selected “Save as draft,” your form will be sent to “Drafts.” Here, you can make edits to forms before you submit them to the final dataset. After you make changes, select “Finalize,” like in step 17.\nAfter selecting “Finalize,” the form is automatically stored under “Ready to send.” In the current version of Kobo, you can still edit forms here. In the future, however, you will not be able to edit once they are finalized, and “Ready to send” will just be a holding place to store finalized forms until you have an internet connection to send them to the server.\nSelect “Send selected” to send all forms to the server.\nTo ensure the forms were uploaded successfully to the server, select “Sent.” These forms are now part of the final dataset."
  },
  {
    "objectID": "pages/full_guide/full_guide_en.html",
    "href": "pages/full_guide/full_guide_en.html",
    "title": "Full Guide for Data Collection",
    "section": "",
    "text": "This document provides guidance and recommendations for administering three survey instruments to capture information about fishing communities and the fisheries they rely on (Figure 1). The surveys were designed to align content with how the data will be used and expected frequency of change. The highest level survey, Community Profiling, contains questions that help to build a better understanding of fishing activity in the community and socioeconomic conditions. Understanding the socioeconomic landscape is especially important when work first begins in a community. The information collected during this survey is essential for designing community engagement strategies and data sampling plans. The Landings Profiling and Monitoring surveys collect data on catch landed by fisheries. The Landings Profiling data is collected less frequently and captures information on fishing habitat, gear type, effort, and length of individual fish. The Landings Monitoring survey, ideally conducted daily, is a rapid fisheries survey collecting the minimum amount of information needed to track catch volume and value changes, such as species, weight, count and price.\n\nFigure 1: Timeline for administering the three different survey instruments on a one year scale."
  },
  {
    "objectID": "pages/full_guide/full_guide_en.html#introduction",
    "href": "pages/full_guide/full_guide_en.html#introduction",
    "title": "Full Guide for Data Collection",
    "section": "",
    "text": "This document provides guidance and recommendations for administering three survey instruments to capture information about fishing communities and the fisheries they rely on (Figure 1). The surveys were designed to align content with how the data will be used and expected frequency of change. The highest level survey, Community Profiling, contains questions that help to build a better understanding of fishing activity in the community and socioeconomic conditions. Understanding the socioeconomic landscape is especially important when work first begins in a community. The information collected during this survey is essential for designing community engagement strategies and data sampling plans. The Landings Profiling and Monitoring surveys collect data on catch landed by fisheries. The Landings Profiling data is collected less frequently and captures information on fishing habitat, gear type, effort, and length of individual fish. The Landings Monitoring survey, ideally conducted daily, is a rapid fisheries survey collecting the minimum amount of information needed to track catch volume and value changes, such as species, weight, count and price.\n\nFigure 1: Timeline for administering the three different survey instruments on a one year scale."
  },
  {
    "objectID": "pages/full_guide/full_guide_en.html#survey-details",
    "href": "pages/full_guide/full_guide_en.html#survey-details",
    "title": "Full Guide for Data Collection",
    "section": "Survey Details",
    "text": "Survey Details\n\nCommunity Profiling Survey\n\n\nGoal\nUnderstand the general landscape of the community and the fisheries operating within the community.\n\n\nData Collected\n\nNumber of community members, fishers, fish traders, women\nGeneral landscape of the fisheries operating within the community\nGears used; species targeted; habitat fished; seasons; vessels\nInformation on fishing effort and cost\nPerceptions on fisheries and habitat conditions, threats\nInformation on current fisheries management/regulations\nIdentification (via mapping) of important fishing grounds, habitats, landing sites \n\n\n\nTarget Audience\n10-20 key informants within the community, namely, community leaders, respected fishers, fish traders, and women.\n\n\nFrequency and Timing\nWhen work begins in a new fishing community, conducting the Community Profiling Survey and the initial profiling exercise provides baseline data and relevant information to design conservation and management efforts most appropriate for the community. Repeating the Community Profiling Survey can help document significant changes occurring over time.\n\n\nMethodology\nInformation can be gathered through third-party surveys (i.e, census, fisheries department records, etc), focus groups consisting of 10-20 key community members or key informants. Community leaders as well as a variety of knowledgeable and diverse fishers and fish traders (including women and young people) would be the ideal participants to include in the focus group. In facilitating the focus groups, it is recommended to have, at a minimum, a facilitator and a note-taker. At the focus group, it is also recommended to have participants provide a list of/contact information for fishers in the community who can then be contacted to administer the Household Surveys.If it is not possible to carry out the Community Profiling Survey in a focus group format, an alternative is to administer the same questions as individual surveys with key informants and pool the responses. Questions included in the community profiling survey and recommendations for conducting focus group discussions can be found here). \n\n\nLandings Monitoring Survey\n\n\nGoal\nCapture key data needed to calculate simple length-based indicators of fishery health and to track changes in fisheries production, value, and composition.\n\n\nData Collected\n\nDate landed\nLanding location\nFish trader name\nFisher name\nFishing Effort (days fishing/gleaning)\nSpecies identity (local, common, scientific names)\nTotal count\nTotal weight\nTotal price\nReason total catch not sold, if applicable\n\n\n\nTarget Audience\nFishers as they land their catch or at a fish buyers’ house/market.\n\n\nFrequency and Timing\nThe Landings Monitoring Survey should be conducted daily or as often as possible. \nPerform Landings Monitoring Surveys before and after implementation to evaluate the effects of fisheries closures or other management strategies. \nWe recommend collecting data 30 days before and after temporary closure periods. For the first seven days of the sampling periods, we recommend that enumerators conduct Landings Monitoring Surveys daily. If possible, continue daily monitoring for the entire 30-day period. If this is not possible, survey at least 80% of days within each 30 days. We also recommend surveying 80% or more of all fishers landing catch on a particular day pre or post-closure. Distribute representative survey efforts between boat fishers and non-boat fishers. Collect data from all fishers landing in the village, regardless of whether or not they were fishing within the closure site.  \nFor longer-term closures, ensure that data is collected during the same month for each year to capture change over the closure period. If that is not feasible, we recommend gathering data during the same month before and after the closure. As stated above, we recommend surveying at least 80% of the day within the month and 80% of fishers landing catch on each day. \n\n\nMethodology\nUsing the Kobo form, meet fishers at landing sites/buyers’ houses to record their catch."
  },
  {
    "objectID": "pages/full_guide/full_guide_en.html#landings-profiling-survey",
    "href": "pages/full_guide/full_guide_en.html#landings-profiling-survey",
    "title": "Full Guide for Data Collection",
    "section": "Landings Profiling Survey",
    "text": "Landings Profiling Survey\n\nGoal\nUnderstand observed catch trends.\n\n\nData Collected\n\nDate landed\nLanding location\nPrimary fishing ground\nFish trader name\nFisher name\nFishing Effort (hours and days fishing/gleaning)\nVessel type (boat registration number, number crew)\nSpecies identity (local, common, scientific names)\nGears used\nHabitat fished\nTotal count\nTotal weight\nTotal price\nReason total catch not sold, if applicable\nSamples of individual weights and lengths (Figures 2, 3, 4, and 5)\nPartner-specific sample data (sex, catch quality, gonads, stylet, # traps, etc.)\n\n\n\nTarget Audience\nA representative sample of catch within the community. Record at least 50 samples (ideally 100) for each target species, representing various gear types and fisher profiles. \n\n\nFrequency and Timing\nThis survey should initially be conducted at the beginning of involvement in a community and subsequently performed every one to two years, before and after implementing the management strategy, or as needed to explain declines observed through monitoring data.\n\n\nFormat\nUsing the Kobo form, meet fishers at landing sites to sample their catch and record their fishing activity.\n\n\nMeasurement Standardization (Length type per species group)"
  },
  {
    "objectID": "pages/full_guide/full_guide_en.html#data-flow-overview",
    "href": "pages/full_guide/full_guide_en.html#data-flow-overview",
    "title": "Full Guide for Data Collection",
    "section": "Data Flow Overview",
    "text": "Data Flow Overview\nBarefoot Ocean processes and analyzes key fisheries and socioeconomic data owned by partnering organizations through data sharing. In other words, partners own the data, and Barefoot Ocean processes it. Data collection, validation, transformation, and visualization are the four major components of the Barefoot Ocean data system. The primary software applications used are KoboToolBox, Smartsheet, PostgreSQL, and R. \nKoboToolBox is a free and open-source software that is a powerful toolkit for data collection accessible through challenging environments and multiple platforms, such as mobile devices, computers, and paper. Enumerators collect data on socioeconomic and ecological conditions essential to assess fishery communities and statuses through the Barefoot Ocean KoboToolBox survey questionnaires. Smartsheet is a collaborative work management platform that provides a flexible and intuitive interface for organizations to plan, track, automate, and manage various projects and processes in real-time. Reference files that are used to populate survey forms and connect additional data to the master datasets are managed in Smartsheet. Additionally, data is validated in Smartsheet. PostgreSQL is a free and open-source database management system used as a data warehouse for numerous web, analytics, and geospatial applications while storing unstructured and structured data in a single product. R is a free and open-source software environment and programming language widely used for data science, statistical computing, and data visualization. Data dashboards are built using the Shiny package from the R programming language and hosted on shinyapps.io, a platform as a service (PaaS) for hosting Shiny web apps (applications).\n\nFigure X: Barefoot Ocean Data Flow diagram.\nData collection involves systematically collecting and measuring information from relevant sources on variables of interest for decision-making, strategic planning, outcome evaluations, and other purposes. By incorporating quantitative and qualitative data in the survey questionnaires, Barefoot Ocean focuses on mixed-method surveys in the data collection process to develop a more in-depth understanding of the socioeconomic and ecological conditions pertinent to fishery communities and adaptive management strategies. Data validation refers to applying methods to measure the conditions of the collected data and determine whether the collected data meets the defined quality criteria, such as accuracy, consistency, relevancy, completeness, and uniqueness. Data transformation converts, cleans, and structures raw data into a usable format that can be analyzed and assessed for decision-making. Data analysis and visualization involves designing and creating accessible graphics or visual displays of information to effectively communicate the complex qualitative and quantitative data previously collected, verified, and transformed across target audiences. We have described the data flow process below:  \n\nData is collected through KoboToolBox survey forms. \nData is pulled into the Barefoot Ocean database. \nIf the enumerator selected pre-populated answer choices in surveys, the data does not need to be validated and can directly go through to the data analysis and visualization process.\nIf the enumerator manually enters data such as a new fisher, buyer, data collector, landing site, or species, the data is verified in Smartsheet before being included in the final data table and visualized in the dashboard. Field team leads are notified via email when data is ready for validation. Team leads will manually check the quality control tables to confirm that the newly added information is valid. \nAfter validation, new data is pushed to both the reference files and back to the database for final transformation before analysis and visualization.\nOnce data is pushed to the reference files, team leads will be notified via email if any additional information is needed in the reference files. \nUpdated reference files are then uploaded to the KoboToolBox platform for inclusion in the forms. \nUpdated data from the reference files are also used in the data transformation process to join additional data fields such as coordinates and gender. \nThe final steps of the data transformation process results in master data tables that are used for data analysis and visualization in the data dashboards. \nData dashboards (i.e. Shiny apps) connect directly to the database, pulling the most up-to-date data available, thereby providing partners near immediate access to raw and summarized data."
  },
  {
    "objectID": "pages/full_guide/full_guide_en.html#data-security",
    "href": "pages/full_guide/full_guide_en.html#data-security",
    "title": "Full Guide for Data Collection",
    "section": "Data Security",
    "text": "Data Security\nBelow is a list of software platforms where data may be stored and moved in transit from the database. Data security information for each external platform is available on the platform-specific website linked here.\n\nKobo software\nPostgreSQL\nAmazon Web Services\nGoogle drive\nSmartsheet(whitepaper on security is located here)\nShinyapps.io\nGithub\n\nBarefoot Ocean has implemented several data security procedures in addition to the data security measures provided by the above software platforms. All accounts on all software platforms used by Barefoot Ocean are password protected.\nWe use Github as our version control system for coded products. By default, all folders and projects with fisheries and socioeconomic data are private and only accessible to Barefoot Ocean staff and contractors. \nFrom any shared data platforms (e.g. Shiny Apps), user authentication is required for viewing or downloading data, depending on the data sharing agreement chosen by each partner organization. This includes verification of users before allowing data to be viewed or downloaded, users logging into data visualization platforms, and regular management of verified users by the Barefoot Ocean team. \nAccess to Smartsheet documents (e.g. reference files, data validation sheets) is restricted to personnel identified by each organization, and each partner may only view their own partner-specific information. Exceptions to this include Barefoot Ocean staff who control and assist with data quality workflows, and Blue Ventures staff assisting partners with information workflows in Smartsheet.\nAccess to Barefoot Ocean’s main database is limited to Barefoot Ocean staff and contractors."
  },
  {
    "objectID": "pages/full_guide/full_guide_en.html#data-privacy",
    "href": "pages/full_guide/full_guide_en.html#data-privacy",
    "title": "Full Guide for Data Collection",
    "section": "Data Privacy",
    "text": "Data Privacy\nPersonal identifiable information (PII) and fisheries catch data is owned by fishers and fish buyers and will never be shared without prior consent. To protect the privacy of fisher, buyers, and data collectors, all names are anonymized into random identification numbers. Therefore, all partially or fully publicly available data will only include the random, numeric id numbers. See the section on data sharing for a full explanation of data sharing agreements.\nData considered to be PII includes:\n\nNames of fishers, buyers, and data collectors\nNames of respondents for any surveys"
  },
  {
    "objectID": "pages/full_guide/full_guide_en.html#data-sharing",
    "href": "pages/full_guide/full_guide_en.html#data-sharing",
    "title": "Full Guide for Data Collection",
    "section": "Data Sharing",
    "text": "Data Sharing\nThe Barefoot Ocean fisheries data system is designed to streamline the utilization of your data and provide a platform for your active engagement in broader fisheries management and conservation efforts. Aggregated data collected collaboratively across partners can yield powerful insights for monitoring the fishery, assessing management strategies, guiding decision-making at both local and national levels, understanding regional changes, and identifying potential financial services.\nWe recognize the critical importance of data ownership and usage for all contributing partners. Our goal is to provide you with flexibility in managing and determining how your data is used. By selecting one of the three data use permission levels, you can regulate the extent to which your data is shared with other users. You can tailor permission levels based on data types, and importantly, you have the freedom to adjust your data permission level at any time. Personal identifiable information (PII) and fisheries catch data is owned by fishers and fish buyers and will never be shared without prior consent. By choosing a data use permission level, you are confirming that individual permissions have been obtained from both fishers and fish buyers.\nAll data is currently set to Level 1 - Private. Users will have the opportunity to adjust their permission levels as needed.\nLevel 1- Private\n\nThe data is strictly for the internal purposes of the original data contributor.\nData will be available for download by the original data contributor.\nData will not be included in regional analyses provided on the dashboard.\nUnauthorized sharing or distribution of the data to external parties is strictly prohibited.\n\nLevel 2 - Share with Other Data Contributors\n\nTrip level data is available for other data contributors to download.\nData summaries and visualizations will be available for other data contributors.\nData will be included in regional analyses on the dashboard.\n\nLevel 3 - Share with All Users\n\nTrip level data is available for all users to download.\nData summaries and visualizations will be available for all users.\nData will be included in regional analyses on the dashboard.\nThe original data contributor may specify any usage limitations or conditions applicable to all users."
  },
  {
    "objectID": "pages/full_guide/full_guide_en.html#validating-new-and-flagged-data",
    "href": "pages/full_guide/full_guide_en.html#validating-new-and-flagged-data",
    "title": "Full Guide for Data Collection",
    "section": "Validating New and Flagged Data",
    "text": "Validating New and Flagged Data\nIn the surveys, some questions allow enumerators to add a new fisher, buyer, data collector, landing site, species, or “other.” Information from these options are new data points and must undergo verification before being pushed to the final dataset, visualized in the dashboard, and added to the reference files. There are also constraints set on weight, price and length of a species, and if the data collected is below or above these constraints, these values are flagged for review. Constraints on weight and price are set by partners in the min_max_ref. Species length constraints are set by the Barefoot Ocean team using biological parameters. \nAll data that flows through the fisheries data system is validated in Smartsheet. Any of these new or flagged entries are sent to the quality control (QA) table in Smartsheet for field teams to validate. The quality control tables are partner-specific and can be accessed via update requests sent to your email or by visiting the Dynamic View links provided to you. Field team leads will be notified via email when data needs to be validated in the QA tables. Once the data have been verified in the QA tables, we will append new information to the reference file and provide necessary corrections to the master dataset. \nSpecific, step-by-step instructions for how to complete data validation in Smartsheet can be found here."
  },
  {
    "objectID": "pages/full_guide/full_guide_en.html#data-collection",
    "href": "pages/full_guide/full_guide_en.html#data-collection",
    "title": "Full Guide for Data Collection",
    "section": "Data Collection",
    "text": "Data Collection\nBarefoot Ocean administers all surveys through Kobo Toolbox forms shareable through a Kobo Toolbox account. You can set up an account here. Please reach out to courtney@barefootocean.org with the account details. Once the surveys are shared, access the Kobo forms through the KoboCollect free Android mobile phone app or via the Enketo web form. Detailed instructions on setting up a Kobo account, collecting data, and submitting data can be found here. Use a QR code to configure all devices after manually setting up the first phone or tablet to set up multiple phones or tablets under one data collection account. Manual setup of the first device requires the Kobo server URL, username, and password. The Kobo server URL is https://kc.kobotoolbox.org. More information on setting up data collection with Kobo, including how to configure multiple data collection devices via a QR code, can be found here. \nOnce you have downloaded KoboCollect, open the app and enter the server URL, username, and password to connect your KoboCollect app to the KoboToolbox server. Connecting the KoboCollect app to the KoboToolbox server allows you to download deployed forms from KoboToolbox to your mobile device and send data collected through the app back to the server. On the home screen, select “Get Blank Form.” A list of all your deployed survey forms should appear. Press “Select All” to have all the survey forms sent to the app, or select the ones you wish to have by selecting them manually. Then click “Get Selected.” To deploy the survey, select “Fill Blank Form.”\nWhile the webform is automatically updated when a new survey version is available, users must configure “auto-update” themselves in the app. Regularly updating the surveys in the app ensures using the latest version of the form and not causing data pipeline issues down the line. You can set up auto-update in the app by going to “Settings” and “Form Management.” More information on automatically updating surveys in the app can be found here, under the section “Form Management Setting in KoboCollect.” It is important to note that a connection is required for the app to pull the most recent survey version, even with auto-update settings turned on. Therefore, advise enumerators to have an internet connection before performing field work so KoboCollect can pull the most recent version.\nAfter collecting data, the surveys submitted via the web form will be automatically submitted to the server once the data collector hits the “Submit” button. Data collected via the KoboCollect app is first saved in the app in a holding place and then pushed to the server. Completed surveys remain on hold before submitting to the server so that data collectors can make survey edits after collecting data, or if there is no internet connection, the app can save the surveys and then push the surveys to the server once there is internet connectivity. Specifically, when the survey is complete, the user will hit “Save form and exit,” ensuring that “Mark form as finalized” is also checked. “Edit Saved Form” automatically stores the saved form. The data collector can make necessary changes and select “Save Form and Exit.” The home screen also has a button called “Send Finalized Form.” Press Select All (or select the ones you wish to upload) and then press “Send Selected.” Select “View Sent Form” to ensure successfully uploading the forms and you should now be able to view all the submitted forms.\nA central data storage system links to the Kobo data, and automated analyses and visualizations will be available through a standardized dashboard. Raw data is backed up in the KoboToolbox database and will be available through download or direct link to another database or data warehouse."
  },
  {
    "objectID": "pages/full_guide/full_guide_en.html#translations",
    "href": "pages/full_guide/full_guide_en.html#translations",
    "title": "Full Guide for Data Collection",
    "section": "Translations",
    "text": "Translations\nTranslations for all languages are completed by editing the translations in Smartsheet. If you find that a translation needs updating or is wrong in the surveys, please directly update the translations Smartsheet file under the appropriate survey tab. If the Barefoot team needs new translations, they will comment and assign the task to the country team lead."
  },
  {
    "objectID": "pages/full_guide/full_guide_en.html#reference-files",
    "href": "pages/full_guide/full_guide_en.html#reference-files",
    "title": "Full Guide for Data Collection",
    "section": "Reference Files",
    "text": "Reference Files\nThe reference files are partner or country-specific and contain comprehensive information on the administrative levels of the fishing communities (country, province, district, village), landing sites, fishers, buyers, data collectors, species data, management areas, habitat types, gear types, and partnering organizations. Some information populates the dropdown lists in the surveys, and some are joined to the master dataset after data is collected. New information should be added directly to the reference sheets.\nSpecific, step-by-step instructions for how to update reference files in Smartsheet can be found here."
  },
  {
    "objectID": "pages/full_guide/full_guide_en.html#appendix-a-focus-group-discussion-guide",
    "href": "pages/full_guide/full_guide_en.html#appendix-a-focus-group-discussion-guide",
    "title": "Full Guide for Data Collection",
    "section": "Appendix A: Focus Group Discussion Guide",
    "text": "Appendix A: Focus Group Discussion Guide\n\nImportant considerations before conducting fisheries profiling or surveys\nRelationship and trust\nBuilding relationships and gaining trust from the community is an important initial step before asking about fisheries information. The first step to building relationships and gaining community trust is introducing yourself, your organization, and the purpose of conducting fisheries profiling.\nPreparation\nPreparation is important in conducting each survey method, as good preparation will give you confidence in the effectiveness of each method you apply.\nTime for collecting information\nAdjust the time of conducting each method to the time of the prospective respondent or targeted community group.\nRespondent\nUnderstanding the potential respondents you will meet during the fisheries profiling is crucial to conducting surveys. Groups or individuals who will be in the survey should receive prior notification. Therefore, introducing influential community leaders must be part of the pre-survey work.\nLogistics\nEach method has logistic and material needs. Make sure that the resources and equipment needed for each method of fisheries profiling have been prepared.\nKey person contact list\nSave a key person contact list on your phone and also have a printed version for back up.\nHealth and safety\nMake sure that you are in a good condition to conduct fisheries profiling. Bring an essential first aid kit."
  },
  {
    "objectID": "pages/full_guide/full_guide_en.html#focus-group-discussion-guidance",
    "href": "pages/full_guide/full_guide_en.html#focus-group-discussion-guidance",
    "title": "Full Guide for Data Collection",
    "section": "Focus Group Discussion Guidance",
    "text": "Focus Group Discussion Guidance\nThe following contains guidance and recommendations on conducting a focus group to capture community profiling information. Holding a focus group session is recommended to encourage dialogue, capture a diversity of opinions, and begin building relationships with important community members. However, in the case that a focus group is not feasible, the community profiling survey can be conducted as individual interviews with important stakeholders using the “Community Profiling Survey” Kobo form. Overall, the goal of the community profiling exercise, whether in a focus group or individual interview format, is to understand the general landscape of the community and the fisheries operating within the community.\n\nPrior to conducting a focus group\nBefore hosting a formal fisheries profiling focus group, it is recommended to conduct informal conversations and participant observation. This method means spending time, building relationships, and understanding the fishery using informal conversation and participant observation.\nInformal conversation is important to better understand the general fisheries context before conducting a focus group discussion. Use this method as one of the starting points to formulate the content of the focus group discussion. This method will allow you to get to know the fisheries community, to start building relationships, and to gain trust.\nRecommended tips to conduct informal conversations:\n\nRespect cultural differences. Observe social norms such as acceptable greetings, dress codes, and respect religious practices. Be polite, humble, and listen to stakeholder opinions without imposing your own. Staying within a community, building a rapport, and sharing meals can help to build trust.\nSpend time with stakeholders. There is no shortcut to gaining trust and support. Especially within communities it is good to be seen, spend time in the villages and meet people. Be prepared to discuss the broader issues within the community. Do not try to push one particular agenda.\nUse the local language if possible, unless a common language is accessible. Otherwise, use an interpreter. Be mindful of errors in translation. Cross checking translation between more than one interpreter can help reduce misinterpretation.\nDo not make promises that cannot be kept. Be clear on objectives and expected outcomes without raising expectations. This is important to emphasize early on so that communities have a clear understanding on the role of the technical partner, i.e. to facilitate the octopus fishery closure, not to dig wells or repair schools. It is important to ensure everyone is aware of what the organization can and cannot do within the community. Ensuring realistic expectations helps to minimize disappointment, complaints, and conflicts as the project progresses.\nCommunicate plans and activities widely. Ensure any meetings or activities are planned in advance and at mutually agreeable times and locations to maximize attendance. Ensure any changes in plans and activities are communicated as early as possible. Being on time and sticking to agreements helps to build trust and confidence between stakeholders.\nAlways acknowledge stakeholders in project outputs such as reports and media releases within stakeholder meetings and external presentations. Be aware of information ‘ownership’ and respect confidentiality and privacy.\n\nBetter understanding the stakeholder landscape in the community is a crucial goal in conducting informal conservations and participant observation. Stakeholders affect or can be affected by an organization’s actions. Their support is essential for an organization’s success in implementing fisheries management plans. By better understanding stakeholders, you will effectively identify stakeholders involved in future fisheries monitoring for fisheries management in their area.\nExamples of types of stakeholders to include:\n\nFishers\nHead of village\nFaith/religious leaders\nHead of district\nCommunity health worker/health practitioner\nVillage buyer/supplier\nProcessing plant\nWomen in the village/fishers’ wives\n\nInformation to be collected about stakeholders:\n\nInformation about key stakeholders and their positions in relation to an entity’s objectives (degree of support, power, etc.). This information can be used to identify which stakeholders to include in the community profiling focus group.\n\nAfter conducting informal conversations, the next step you can do is participant observation. Observation is a method that allows you to use the events around you to gather clues and generate conclusions about specific locales or experiences by observing a day in the fishing village. This method is necessary to gather evidence from the information provided in informal conversations. This method allows you to understand the fishing village’s daily life activities.\n\n\nFocus Group Procedures\n\nOrganizing the focus group\n\n\nIt is important to maintain good relationships with target communities. Therefore, wherever possible villages should be informed of the programme for the focus group meeting at least two weeks in advance.\nIf the village has mobile phone reception, call the head of the village or other local contact(s).\nIf the village does not have mobile phone reception, conduct a visit to the village to meet with the head of village or other local contact(s).\nDuring this phone call or visit with the village president or other local contact(s), explain the following:\n\nAim of the meeting\nLocation of the meeting\nDate and time of the meeting\nMethod of informing participants of the meeting\nNumber of participants\n\nAll villagers or special people based on best fishers (2)\nMost frequent fishers (2)\nFishers that frequent many different fishing sites (2)\nWell-respected fishers preferably with experience in mapping (2)\n\n\nWomen - check with the head of the village if the focus group can take place with both sexes present together in advance as in some areas, this is not always possible.\nTry to avoid conducting the meeting(s) during spring tides/high fishing season, as many of the required fishers will likely be busy fishing.\nBe sure to check schedules of other projects that might be working in the same area at the same time to avoid clashes.\n\n\nFocus group team\n\nThe following are the recommended roles for the team leading the focus group. At a minimum, a focus group should have a facilitator and a note-taker.\nLead facilitator: Leads and moderates the meeting\n\nIntroduces the meeting\nFacilitates the event\nModerates the process\nActs as a catalyst between the individuals of the group\nFinds ways of integrating dominant and quiet people and makes sure that all group members are able to express their opinions\nMakes sure that the group keeps to the topic but is also flexible in handling additional important information\nRepeats in own words what people say in order to confirm that there is a good understanding of the discussion\nTakes care of time management\n\nFacilitator Assistant: Assists the lead facilitator, especially in displaying visual aids\n\nSupports the note-taker in gathering all relevant information\nLeads the displaying of visual aids and assists with other interactive components of the meeting such as tallying votes, taking notes that are displayed, passing out materials, etc.\nBrings along the necessary material\nAssists the facilitator in an indirect way by giving signs (e.g., pointing out those who wish to speak). \nSupports the facilitator directly by asking questions, if the situation requires it.\n\nNote-taker: Documents the meeting\n\nObserves the event from the background\nCaptures all responses. It is helpful to have the question list printed so it can be annotated with notes during the meeting.\nWrites down all important information\nNotes who is talking. Is there an equal participation of all or do some people dominate the process? Do women talk?\n\n\nFocus group participants\n\nCarefully plan who to invite to the focus group meeting. Identifying 10-12 individuals is recommended to ensure the size is manageable, allowing for adequate representation of different perspectives. As much as possible, include representatives from diverse stakeholder groups and community sectors (see examples of types of stakeholders in the section above). When selecting participants, account for their knowledge and roles in the community. Inviting people more knowledgeable about the fisheries and the community, such as a full-time fisher rather than an occasional recreational fisher, will provide more robust and accurate information. Identifying and inviting people who are well-respected in the community helps build trust.\n\nDiscussion logistics and methodology\n\nData can be captured in the “Community Profiling Survey” Kobo form. However, it may be easier for the note-taker to capture the data via written notes in order to more easily capture nuances and information that arise from the group discussion, such as differing answers per respondent. If the information is collected by taking notes. After the focus group meeting has been completed, the responses should be entered into the “Community Profiling Survey” Kobo form. \nEncourage all members of the group to speak as they represent a mixture of ages and social standings that may have different experiences of the fishery.\nPosing questions one by one to the group and waiting for volunteers to respond is one approach to leading a discussion. However, varying how the facilitator solicits responses can help keep the discussion interesting and also ensure that all voices are heard and less vocal participants are able to participate. Prior to beginning the focus group, think through how you would like to elicit responses for each planned question.\n\nOpen forum – Anyone can respond to the question and speak.\nCall on specific participants – This can help ensure that less vocal participants are given a chance to speak. This can be used later in the discussion once the facilitator has a sense of which participants may benefit from being called on. Alternatively, a facilitator may use this technique when they know a certain participant has important knowledge or information related to a question.\nQuick response – Go in a circle and each person very briefly shares their opinion/response to the question. This can be effective in polling the audience as it involves everyone. However, be sure to clearly communicate and enforce time limits or this method can end up draining too much discussion time.\nVote – Poll the audience by asking a question and having people raise their hand in accordance with different response options. This can be done openly or anonymously with eyes closed or with people writing their responses on folded pieces of paper that are then collected.\nGroups – Split the group into smaller groups who discuss and report back to the main group. This technique is especially helpful with large groups when there is not enough time for all group members to participate in the full group forum. In this situation, make sure that each group has stakeholders representing different opinions and perspectives.\n\n\n\nFocus Group Questions\nBegin the focus group by introducing yourself, the project, and the goal of the meeting. Then, have everyone in the room introduce themselves. Plan the best methods for each question to elicit and collect responses beforehand (see section above for ideas). Please see the Community Profiling Survey document for the full list of focus group questions to walk through.\n\n\nFacilitation Resources\n\nFacilitator Core Competencies – International Association of Facilitators (IAF)\nFacilitator’s Meeting Checklist – Social Transformation Project, Tools for Transformation\nIntroduction to Planning and Facilitating Effective Meetings – Social Science Tools for Social Programs, NOAA Coastal Services Center\nGroup Facilitation and Problem-Solving – Community Tool Box, Center for Community Health and Development at the University of Kansas\n\nSection 1:Conducting Effective Meetings\nSection 2:Developing Facilitation Skills\nSection 3:Capturing What People Say: Tips for Recording a Meeting\nSection 4:Techniques for Leading Group Discussions"
  },
  {
    "objectID": "pages/quick_guide/quick_guide_en.html#quick-guide-fisheries-and-community-data-collection-guidance",
    "href": "pages/quick_guide/quick_guide_en.html#quick-guide-fisheries-and-community-data-collection-guidance",
    "title": "Quick Guide",
    "section": "",
    "text": "The quick guide provides step-by-step guidance to collect and validate fisheries and community data through the system developed by Barefoot Ocean. This guidance summarizes the data collection process and outlines the protocols for updating reference files and quality control tables. A full guide with further details on the Fisheries Data Collection system can be found in the Training Materials folder linked below.\nWe developed four survey forms to collect data on fisheries landings and fishing communities. Detailed survey descriptions are available in the full guide in English, Bahasa Indonesian, Cebuano, French, Tagalog, Swahili, Malagasy, Spanish, Portuguese, and Tetun translations here.\nThe Landings Monitoring Survey captures the minimum data, ideally daily or as often as possible, needed to track long-term trends in fisheries production, species composition, and catch value. This survey can help evaluate the effects of fisheries closures or other management strategies by comparing data before and after implementation. The survey is short and user-friendly to allow for more frequent and consistent data collection.\nThe Landings Profiling Survey collects detailed fisheries data on gear, effort, and size of individual fish or invertebrates alongside specialized information for specific species groups such as sex, catch quality, stylet data, and egg maturity. Catch quality of octopus includes storage methods, color, tentacle number, physical abrasions, beak quality, and skin conditions. Octopus stylet data includes sample photos and growth circumference. Egg maturity data accounts for gonad weight, color, stage, length, and line appearances in the ovary glands of female octopuses. These data complement the landings monitoring data and help partners better understand observed catch trends in fisheries production and the effects of fisheries management. The survey was designed to be performed at the beginning of involvement in a community and subsequently conducted every one to two years, before and after implementing the management strategy, or as needed to explain changes in catch observed through monitoring data.\nThe Community Profiling Survey gathers a comprehensive understanding of the socio-economic and fisheries landscape of a community. The survey is used when first engaging with a community and repeated when appropriate to document major shifts in fishing behavior, fisher perceptions, and resource management. Survey frequency will depend on project scope (i.e., when a change is expected to occur) or\nThe Fisher Household Survey captures detailed fisher household information, such as household-level perceptions of fishing-related activities, income sources, daily activities, main fish species caught, reliance on fish for food, and fishing activity. The survey is used when first engaging with a community and repeated every two to five years or after management interventions to document shifts in fishing behavior, fisher perceptions, management effectiveness, food security, trust, and gender equity.\nSteps for Using KoboToolbox Forms\n\nPrepare reference data\n\nReference data can be updated via Smartsheet and contains comprehensive information on the administrative levels of the fishing communities (country, province, district/municipality, village/community), landing sites, fishers, buyers, data collectors, species data, management areas, habitat types, gear types, and partnering organizations.\nReference data sheets are used to populate dropdown lists in the KoboToolBox survey forms and join additional data needed for analysis such as village coordinates and fisher gender.\nUpdate reference data with new species, fishers, buyers, landing sites, villages, etc. that are needed for data collection in new areas. Specific, step-by-step instructions for how to update reference files in Smartsheet can be found here.\nWhen adding a new entry, BFO automatically receives notification, so there is no need to comment to let us know you’ve added new data. Please do let us know, however, if an existing entry changes by commenting and describing the change.\nIt is critical that these files are up to date in order for data collection and analysis to run smoothly. Reference files are uploaded to kobo everyday at 9am EST.\n\nSet up the KoboToolbox Account\n\nAll surveys are administered through the use of a KoboToolBox form. Each of the survey forms can be shared with a KoboToolBox account. Set up your KoboToolbox Account here on the general server. Please reach out to courtney@barefootocean.org with account details and the forms will be shared with your account.\n\nDownload the KoboCollect App.\n\nThe Kobo forms can be accessed through the KoboCollect free Android mobile phone app or via Enketo web form.\n\nLoad forms in KoboCollect App (detailed instructions found here).\n\nOnce the app is downloaded, set up the server URL, Username, and Password, which connects your KoboCollect app to the KoboToolbox server. This allows you to download deployed forms from KoboToolbox to your mobile device and also send data collected through the app back to the server. For the URL, use the general use server URL - https://kc.kobotoolbox.org. You can access “Project Settings” by clicking the icon in the top right hand corner of the home screen. On the home screen, select “Download Form.” A list of all your deployed survey forms should appear. Press “Select All” to have all the survey forms sent to the app or select the ones you wish to have by selecting them manually. Then, click “Get Selected.” It is important that the surveys are regularly updated to ensure the latest version of the form is being used so as to not cause issues in the data pipeline down the line. While the webform is automatically updated when a new version of the survey is available, users must configure “auto-update” in the app. You can set up auto-update by going to “Settings” and “Form management”. Additional information on automatically updating surveys in the app can be found here.\n\nCollect data with the KoboToolBox survey forms\n\nCollect data by selecting “Start New Form” in the KoboCollect app. See detailed instructions on collecting data using the app here. At the end of the survey, select “Finalize.” If you want to edit the form before submitting, select “Save as draft.” If you selected “Save as draft,” your form will be sent to “Drafts.” Here, you can make edits to forms before you submit them to the final dataset. After you make changes, select “Finalize,” as mentioned above. After selecting “Finalize,” the form is automatically stored under “Ready to send.” In the current version of Kobo, you can still edit forms here. In the future, however, you will not be able to edit once they are finalized, and “Ready to send” will just be a holding place to store finalized forms until you have an internet connection to send them to the server. Select “Send selected” to send all forms to the server. Data collected using the app or web form will be cleaned and stored in a central data storage system. Raw data is backed up in the KoboToolbox database.\n\nValidate data in Smartsheet\n\nAll data that flows through the fisheries data system is validated in Smartsheet. A full step-by-step instruction guide for completing data validation can be found here.\nData is sent for validation under two scenarios; 1) new names for a fisher, buyer, data collector or species are manually added in Kobo Collect, or 2) a numeric value falls beyond established thresholds. These entries must be verified before being included in the final dataset, visualized in the dashboard, and added to the reference files.\nAny new names or flagged data are sent to the relevant quality control (QA) table in Smartsheet for field teams to validate. The quality control tables are partner-specific and can be accessed via update requests sent to your email or by visiting the Dynamic View links provided to you. Field team leads will be notified via email when data needs to be validated in the QA tables.\nValidating new names: When a new name is entered during data collection, these entries are automatically cross-referenced against the reference files to assess whether new entries might already exist in the reference files, but perhaps spelled differently. Any similar existing entries will be added to the QA table under the “ref_match” columns. Team leads can then easily verify if the “new” data is in fact already in the reference files. Team leads will complete the “validation_options” column in each QA table by selecting either new_datae, the cross-referenced data entry from the reference file (i.e. a “ref_match”), other, or remove. If “other” is selected, you must provide a name in the “other” column. If it’s a new local species name that needs to be validated, a column with the photo taken during data collection will be provided for reference.\nValidating numeric values with threshold warnings: For any flagged data entries, team leads will complete data validation in the “correct” column by selecting Y (yes, values are correct), N (no, values are not correct), or remove (data cannot be validated and should be removed from the master dataset). If no is selected, correct values for the numerator or denominator should be entered in the “correct_numerator” and “correct_denominator” columns.\nOnce the data have been verified in the QA tables, we will append new information to the reference file and provide necessary corrections to the master dataset.\n\nUpdate translations sheet\n\nTranslations for all languages are completed by editing the translations Google Sheet. If you find that a translation needs updating, please directly update the Google Sheet, highlight the updated row in yellow, and add a comment assigning the task by typing “@” or “+” followed by the email addresses alice@barefootocean.org and brittany@barefootocean.org. If new translations are needed, the Barefoot team will comment and assign the task to the country team lead.\n\nVisualize and use data\n\nAutomated analyses and visualizations will be available through standardized dashboards. Datasets will also be available through download or direct link to another database or data warehouse.\nPlease let us know if you have any questions.\nThank you!\nBarefoot Ocean Team\nBarefoot Ocean Contacts\nCourtney - courtney@barefootocean.org\nBrittany - brittany@barefootocean.org\nKatie- katie@barefootocean.org\nLaura- laura@barefootocean.org"
  },
  {
    "objectID": "pages/data_validation/data_validation_en.html",
    "href": "pages/data_validation/data_validation_en.html",
    "title": "Data Validation",
    "section": "",
    "text": "All data that flows through the fisheries data system is validated in Smartsheet. Data is sent for validation under two scenarios; 1) new names are manually added in Kobo Collect, or 2) a numeric value falls beyond established thresholds. Once data is validated, both the master datasets in the database and the reference tables are updated. Reference tables serve as inputs for dropdown lists in KoboToolbox forms and contain data that is added to the master datasets through joins. See the decision tree below (Figure 1).\nData triggered for validation is sent to one of three tables: 1) Landings Name QA, 2) Species QA, or 3) Value Warnings QA. The instructions below detail the data validation process in Smartsheet for the three validation tables. Each validation table will require either selecting the correct field value from a dropdown list or entering correct values manually. The process will be appended for future data validation needs, as required.\nStep 1: Provide Barefoot Ocean with point of contact email addresses for those responsible for data validation.\n\nThe organization managing multiple partners may provide all points of contact information.\nIndividual partners may provide point of contact information.\nThe points of contact will receive data validation notifications through email.\n\nStep 2: Check your email for a data validation request.\n\nYou will receive an email from �Smartsheet Automation� (Figure 2)\nThe email will contain a message with links to proceed with validation through either a �Dynamic View� or �Open Request�. Dynamic View is a table format and Open Request will direct you to a validation form.\nTo open with �Dynamic View� (Step 3, Option A), click the link that begins with �https://dynamicview.smarthseet.com�.�\nTo open the update request form (Step 3, Option B), click the blue �Open request� button\nA preview of the entries that need to be validated will appear below this message, but you will not be able to validate any data directly in the email\nAt the bottom of the email, there is a link for �Go to the sheet�; however, the underlying sheet has restricted access. Please review your data validation via Dynamic view, Open request, or your partner-specific report (coming soon).\n\nFigure 1: Data validation decision tree.\nFigure 2: Sample Smartsheet Validation Email Message\nStep 3, Option A: Complete your data validation via Dynamic View (recommended)\n\nFor this option, you will need to create a free Smartsheet account. You will be directed from the email to set up an account.\nClick on the Dynamic View link in the email request.\nA new internet browser window will open with a table-like setup for all entries. Here, you can easily scroll through all the entries that need validation.\nClick on a row to begin validation.\nA �Details� panel will appear on the right.\nReview the context fields and populate the validation fields. The validation fields contain the data that will be transferred to the final dataset (Table 1).\nLeave a comment, ONLY IF there is something that needs our attention. Barefoot Ocean staff will review comments and respond appropriately.\nClick the blue �Save� button to save your selection.\nOnce validated, that row will disappear from your dynamic view.\nClick on the next row and repeat steps to complete validation for all entries.\nYou can exit and re-enter by clicking on the dynamic view link from your email or logging into your account at any time. You do not need to validate all entries in one sitting.\nYou can bookmark this link and return at any time.\n\nTable 1: Primary fields in the validation tables. Context fields provide information needed to validate data. Validation fields are populated with data that will be transferred to the master datasets. Only the validation field can be edited. Some fields are only visible in the �Details� panel when a row is clicked in the Dynamic View table.\nValidation table field | Field description | Field type |"
  },
  {
    "objectID": "pages/data_validation/data_validation_en.html#fisheries-data-validation-guide",
    "href": "pages/data_validation/data_validation_en.html#fisheries-data-validation-guide",
    "title": "Data Validation",
    "section": "",
    "text": "All data that flows through the fisheries data system is validated in Smartsheet. Data is sent for validation under two scenarios; 1) new names are manually added in Kobo Collect, or 2) a numeric value falls beyond established thresholds. Once data is validated, both the master datasets in the database and the reference tables are updated. Reference tables serve as inputs for dropdown lists in KoboToolbox forms and contain data that is added to the master datasets through joins. See the decision tree below (Figure 1).\nData triggered for validation is sent to one of three tables: 1) Landings Name QA, 2) Species QA, or 3) Value Warnings QA. The instructions below detail the data validation process in Smartsheet for the three validation tables. Each validation table will require either selecting the correct field value from a dropdown list or entering correct values manually. The process will be appended for future data validation needs, as required.\nStep 1: Provide Barefoot Ocean with point of contact email addresses for those responsible for data validation.\n\nThe organization managing multiple partners may provide all points of contact information.\nIndividual partners may provide point of contact information.\nThe points of contact will receive data validation notifications through email.\n\nStep 2: Check your email for a data validation request.\n\nYou will receive an email from �Smartsheet Automation� (Figure 2)\nThe email will contain a message with links to proceed with validation through either a �Dynamic View� or �Open Request�. Dynamic View is a table format and Open Request will direct you to a validation form.\nTo open with �Dynamic View� (Step 3, Option A), click the link that begins with �https://dynamicview.smarthseet.com�.�\nTo open the update request form (Step 3, Option B), click the blue �Open request� button\nA preview of the entries that need to be validated will appear below this message, but you will not be able to validate any data directly in the email\nAt the bottom of the email, there is a link for �Go to the sheet�; however, the underlying sheet has restricted access. Please review your data validation via Dynamic view, Open request, or your partner-specific report (coming soon).\n\nFigure 1: Data validation decision tree.\nFigure 2: Sample Smartsheet Validation Email Message\nStep 3, Option A: Complete your data validation via Dynamic View (recommended)\n\nFor this option, you will need to create a free Smartsheet account. You will be directed from the email to set up an account.\nClick on the Dynamic View link in the email request.\nA new internet browser window will open with a table-like setup for all entries. Here, you can easily scroll through all the entries that need validation.\nClick on a row to begin validation.\nA �Details� panel will appear on the right.\nReview the context fields and populate the validation fields. The validation fields contain the data that will be transferred to the final dataset (Table 1).\nLeave a comment, ONLY IF there is something that needs our attention. Barefoot Ocean staff will review comments and respond appropriately.\nClick the blue �Save� button to save your selection.\nOnce validated, that row will disappear from your dynamic view.\nClick on the next row and repeat steps to complete validation for all entries.\nYou can exit and re-enter by clicking on the dynamic view link from your email or logging into your account at any time. You do not need to validate all entries in one sitting.\nYou can bookmark this link and return at any time.\n\nTable 1: Primary fields in the validation tables. Context fields provide information needed to validate data. Validation fields are populated with data that will be transferred to the master datasets. Only the validation field can be edited. Some fields are only visible in the �Details� panel when a row is clicked in the Dynamic View table.\nValidation table field | Field description | Field type |"
  }
]